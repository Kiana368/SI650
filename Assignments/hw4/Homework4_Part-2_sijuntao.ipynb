{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZegaoMgrYwh"
   },
   "source": [
    "# Homework 4, Part 2\n",
    "\n",
    "In Part 1, we saw how to create a bi-encoder to estimate the relevance of a query-document pair and generate these relevance scores. In Part 2, we'll see how to integrate those scores into a learning to rank (L2R) model with a few features.\n",
    "\n",
    "For this part, you are going to:\n",
    "1. Create the dataset ready to use for Pyterrier.\n",
    "2. integrate the cosine similarity you have got in part 1 into the features of learning to rank models.\n",
    "\n",
    "\n",
    "Learning goals for Homework 4, Part 2:\n",
    "* Improve familiarity with installing and running Pyterrier code\n",
    "* Learn how to use L2R models in Pyterrier\n",
    "* Learn how to add custom features to L2R models with Pyterrier.\n",
    "* Deepen your understanding of how different models perform in mixed-domain settings (e.g., text queries / code docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: install things as needed\n",
    "\n",
    "In case you didn't do any of Homework 3 (which was extra credit), please be sure to have the following libraries installed and ready. The installation command is commented out for now but uncomment and run each as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastrank\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCChI82b5QgT"
   },
   "source": [
    "# Task 1: Creating a dataset with precomputed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrEsm8o1xr86"
   },
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e98PFUU7xx4e"
   },
   "source": [
    "Load in the dataset used for evaluation as a pandas data frame, which is in `final_evaluation_set.csv`. Then print the number of unique queries (99), unique code-documents in the dataset (958) to verify it was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "958\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "fes = pd.read_csv(\"data/final_evaluation_set.csv\")\n",
    "print(len(fes['Query'].unique()))\n",
    "print(len(fes['GitHubUrl'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgalx8xSyUuN"
   },
   "source": [
    "## Task 1.2: Creating an index  (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxRnZjD0yWsO"
   },
   "source": [
    "Since the code documents are text, we can still create an index to store them (just like regular documents before). Before, we mostly used pre-built indices or loaded them from file. In this part, you'll see how to create your own index from a pandas dataframe. \n",
    "\n",
    "The rough steps are as follows:\n",
    "* Start pyterrier\n",
    "* Map each unique code document to a unique string identifier (keep this around in a dictionary!)\n",
    "* Create a pandas DataFrame of each unique code-document with two columns:\n",
    "  * `text` containing the contents of the code-document \n",
    "  * `docid` a unique string identifier for that code-document\n",
    "* use pyterrier's [`DFIndexer`](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html) to create an index from the data frame.\n",
    "\n",
    "Once you're finished with these steps, print the collection statistics, which should look something like this:\n",
    "```\n",
    "Number of documents: 958\n",
    "Number of terms: 4929\n",
    "Number of postings: 26358\n",
    "Number of fields: 0\n",
    "Number of tokens: 65017\n",
    "Field names: []\n",
    "Positions:   false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set this based on where Java is installed\n",
    "# !export JAVA_HOME=/usr/lib/jvm/java-18-openjdk-amd64/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Start pyterrier\n",
    "import os\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(tqdm='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each unique code document to a unique string identifier (keep this around in a dictionary!)\n",
    "ucd_dict = {}\n",
    "ucd_list = list(fes['GitHubUrl'].unique())\n",
    "i = 0\n",
    "for ucd in ucd_list:\n",
    "    ucd_dict[ucd] = 'd' + str(i)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame of each unique code-document with two columns 'text' and 'docno'\n",
    "fes_uni = fes.drop_duplicates('GitHubUrl')[['GitHubUrl','code']].rename(columns = {'code':'text'})\n",
    "fes_uni_docid = []\n",
    "for i in range(len(fes_uni)):\n",
    "    fes_uni_docid.append(ucd_dict[fes_uni.iloc[i]['GitHubUrl']])\n",
    "fes_uni['docno'] = fes_uni_docid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 958\n",
      "Number of terms: 4929\n",
      "Number of postings: 26358\n",
      "Number of fields: 0\n",
      "Number of tokens: 65017\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use pyterrier's DFIndexer to create an index from the data frame\n",
    "index_dir = './code_index'\n",
    "indexer = pt.DFIndexer(index_dir, overwrite=True)\n",
    "index_ref = indexer.index(fes_uni[\"text\"], fes_uni[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYYzIVPfzXqo"
   },
   "source": [
    "## Task 1.3: Preparing the query data\n",
    "\n",
    "We'll be using Pyterrier's `Experiment` framework to do our evaluation so we'll need to organize our queries in the test set into a pandas `DataFrame`. Create a new dataframe for all unique queries with two columns:\n",
    "* `query` the text of the query\n",
    "* `qid` a unique string identifier for that query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m4ATKtaJ9cl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>write csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unzipping large files</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>unique elements</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>underline text in label widget</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>string to date</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query qid\n",
       "0                        write csv   0\n",
       "10           unzipping large files   1\n",
       "20                 unique elements   2\n",
       "30  underline text in label widget   3\n",
       "40                  string to date   4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "queries = fes[['Query']].drop_duplicates()\n",
    "queries['qid'] = np.arange(0,99)\n",
    "queries['qid'] = queries['qid'].astype(str)\n",
    "queries = queries.rename(columns = {'Query':'query'})\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9xA-O3l1yoS"
   },
   "source": [
    "## Task 1.4: Preparing the Evaluation data\n",
    "\n",
    "In the final step, we'll create a single data frame that contains the queries, documents, and true relevance scores, which we'll use to evaluate our models using `pt.Experiment`. Your dataframe should have three columns:\n",
    "* `qid` the unique string identifier for a query\n",
    "* `docno` the unique string identifier for a code-document\n",
    "* `label` the relevance score for that query-document pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s-FIvfDe-ZoB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>d2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>d3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>d4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid docno  label\n",
       "0   0    d0      3\n",
       "1   0    d1      3\n",
       "2   0    d2      3\n",
       "3   0    d3      3\n",
       "4   0    d4      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "qrels = pd.merge(queries, fes, left_on = 'query', right_on = 'Query')\n",
    "qrels = pd.merge(qrels[['qid','code','relevance']], fes_uni, left_on ='code',right_on = 'text')\n",
    "qrels = qrels[['qid','docno','relevance']].rename(columns = {'relevance':'label'}).drop_duplicates()\n",
    "qrels['qid'] = qrels['qid'].astype(str)\n",
    "qrels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnIdJWty5LcI"
   },
   "source": [
    "# Task 2: Learning to Rank\n",
    "\n",
    "The steps in Task 2 will have you running some evaluations and setting up a Learning to Rank model that we'll extend later to incorporate the bi-encoder features.\n",
    "\n",
    "First, we'll split our labeled query-document data into train, development, and test sets so we can train models and evaluate unsupervised models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some characters in the query have a special meaning in the Terrier query language. \n",
    "# strip them out using the Tokeniser\n",
    "def strip_markup(text):\n",
    "    tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "    return \" \".join(tokeniser.getTokens(text))\n",
    "\n",
    "queries =  pt.apply.query(lambda r: strip_markup(r.query))(queries)\n",
    "queries = queries[['query','qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "from sklearn.model_selection import train_test_split\n",
    "tr_va_topics, test_topics = train_test_split(queries, test_size=30, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1Zl0NVF3DSl"
   },
   "source": [
    "## Task 3.1: Test baseline models (5 points)\n",
    "\n",
    "In this initial step, create two `BatchRetrieve` rankers that use \"BM25\" or \"TF_IDF\" and run an `pt.Experiment` using them on the code index, using \"map\" and \"ndcg\" to evaluate their performance. We'll evaluate these only on the test data (no hyperparameter fine-tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kpVQoPjf_Ie8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.778419</td>\n",
       "      <td>0.825697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.829723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name       map      ndcg\n",
       "0    BM25  0.778419  0.825697\n",
       "1  TF-IDF  0.778695  0.829723"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25,tf_idf],\n",
    "    test_topics,\n",
    "    qrels,\n",
    "    names=['BM25','TF-IDF'],\n",
    "    eval_metrics=[\"map\", \"ndcg\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTRT5STU5DNP"
   },
   "source": [
    "## Task 3.2: Creating our first pipeline (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZKm-fDK5gIL"
   },
   "source": [
    "Let's start getting more complex with our pipelines. Create a feature pipeline that has three features:\n",
    "1.   the BM25 code score;\n",
    "2.   the TF-IDF code score;\n",
    "3.   the coordinate match score for the query--i.e. how many query terms appear in the code;\n",
    "\n",
    "We'll use these features later in learning to rank. Fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BCjbuTRHFUzy"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "ltr_feats1 = bm25 >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # tf-idf\n",
    "    tf_idf\n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\") \n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"TF-IDF\", \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrU8hJ-q6VTP"
   },
   "source": [
    "## Setting up the Learning to Rank (L2R) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qu8tqrxn6sRr"
   },
   "source": [
    "For the next part, you won't need to write any code (we've done it for you) but you will need to run the cells to train a few different kinds of L2R models on the training set. Each of the models captures a different kind of L2R that we talked about.\n",
    "\n",
    "Train the following three models on our training set:\n",
    " - random forests from `scikit-learn`, a pointwise regression tree technique\n",
    " - coordinate ascent from FastRank, a listwise linear technique\n",
    " - LambdaMART from LightGBM, a listwise regression tree technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m79Yflq0Fu99",
    "outputId": "7b6ea521-0555-44ee-f840-cf5e347422d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 s, sys: 153 ms, total: 4.85 s\n",
      "Wall time: 3.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "\n",
    "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
    "\n",
    "%time rf_pipe.fit(train_topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NphW4hlFzVA",
    "outputId": "0f6953fa-42ed-4c5d-cfa6-387d1fa74deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|2               |    0.000|    0.803\n",
      "   4|2               |    0.000|    0.801\n",
      "   3|0               |    0.000|    0.806\n",
      "   0|0               |    0.000|    0.298\n",
      "   3|2               |   -0.455|    0.806\n",
      "   4|0               |    0.468|    0.802\n",
      "   3|2               |   -0.555|    0.809\n",
      "   3|2               |   -0.755|    0.813\n",
      "   2|2               |   -0.409|    0.804\n",
      "   1|1               |    0.859|    0.803\n",
      "   1|1               |    0.959|    0.803\n",
      "   0|2               |    0.554|    0.299\n",
      "   1|1               |    1.559|    0.803\n",
      "   0|2               |    0.654|    0.300\n",
      "   1|1               |    2.359|    0.803\n",
      "   0|2               |    0.854|    0.300\n",
      "   1|1               |    3.959|    0.803\n",
      "   0|2               |    1.254|    0.304\n",
      "   0|2               |    2.054|    0.335\n",
      "   0|2               |    3.654|    0.487\n",
      "   1|1               |   26.359|    0.803\n",
      "   2|1               |   -0.237|    0.805\n",
      "   0|2               |    6.854|    0.592\n",
      "   0|2               |   13.254|    0.598\n",
      "   0|2               |   26.054|    0.598\n",
      "   0|2               |419430.854|    0.598\n",
      "   1|0               |    0.007|    0.803\n",
      "   1|0               |   -0.015|    0.803\n",
      "   4|1               |    1.101|    0.803\n",
      "   4|1               |    5.901|    0.803\n",
      "   4|1               |   12.301|    0.803\n",
      "   4|1               |  101.901|    0.803\n",
      "   2|0               |    0.432|    0.805\n",
      "   4|1               |  409.101|    0.803\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|0               |    0.000|    0.813\n",
      "   0|1               |    0.000|    0.788\n",
      "   4|1               |104857.101|    0.803\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|2               |   -0.150|    0.804\n",
      "   4|2               |   -0.750|    0.806\n",
      "   1|2               |   -0.150|    0.804\n",
      "   1|2               |   -0.750|    0.806\n",
      "   0|1               |    0.031|    0.788\n",
      "   0|1               |    0.124|    0.788\n",
      "   0|1               |    0.248|    0.795\n",
      "   0|1               |    0.496|    0.797\n",
      "   0|1               |    0.991|    0.801\n",
      "   0|1               |    1.983|    0.802\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.802\n",
      "   1|0               |   -0.009|    0.807\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|0               |    0.000|    0.806\n",
      "   2|2               |   -0.358|    0.806\n",
      "   2|2               |   -0.458|    0.807\n",
      "   1|0               |   -0.065|    0.807\n",
      "   1|0               |   -0.121|    0.810\n",
      "   0|0               |    0.750|    0.803\n",
      "   4|0               |   -0.002|    0.806\n",
      "   4|0               |   -0.010|    0.806\n",
      "   4|0               |   -0.079|    0.807\n",
      "   4|0               |   -0.157|    0.813\n",
      "   1|1               |    0.456|    0.812\n",
      "   0|2               |    0.142|    0.803\n",
      "   0|2               |   -0.558|    0.805\n",
      "   0|2               |   -1.358|    0.807\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|1               |    0.225|    0.810\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Finished successfully.\n",
      "CPU times: user 3.54 s, sys: 89.9 ms, total: 3.63 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "import fastrank\n",
    "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "\n",
    "params = train_request.params\n",
    "params.init_random = True\n",
    "params.normalize = True\n",
    "params.seed = 1234567\n",
    "\n",
    "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "\n",
    "%time ca_pipe.fit(train_topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9nYe5q4GPk3",
    "outputId": "62b53783-b25f-4e59-9617-2eed5624f04f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "CPU times: user 2.02 s, sys: 67.1 ms, total: 2.09 s\n",
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[20]})\n",
    "\n",
    "%time lmart_x_pipe.fit(train_topics, qrels, valid_topics, qrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.4: Comparing L2R performance (10 points)\n",
    "\n",
    "Now that we have all of our models, let's compare them with the baselines we had before. Run another `Experiment` that compare the three L2R models with the two baselines (BM25 and tf-idf). This time, we'll add \"ndcg_cut_10\" to see their performance on just the top 10 docs and \"mrt\" to see how fast the models are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "AKS9nTDvGjnz",
    "outputId": "f60d7628-f53e-4c17-ca54-f2d4664a43ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.790156</td>\n",
       "      <td>0.839688</td>\n",
       "      <td>0.756826</td>\n",
       "      <td>22.880874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.687240</td>\n",
       "      <td>0.783316</td>\n",
       "      <td>0.668496</td>\n",
       "      <td>30.115269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.685549</td>\n",
       "      <td>0.727322</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>22.623268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.778419</td>\n",
       "      <td>0.825697</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>3.882451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.829723</td>\n",
       "      <td>0.746016</td>\n",
       "      <td>3.657715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map      ndcg  ndcg_cut_10        mrt\n",
       "0       fastrank  0.790156  0.839688     0.756826  22.880874\n",
       "1  random forest  0.687240  0.783316     0.668496  30.115269\n",
       "2     LambdaMart  0.685549  0.727322     0.614833  22.623268\n",
       "3           bm25  0.778419  0.825697     0.744078   3.882451\n",
       "4         tf-idf  0.778695  0.829723     0.746016   3.657715"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "pt.Experiment(\n",
    "    [ca_pipe, rf_pipe, lmart_x_pipe,bm25, tf_idf], \n",
    "    test_topics,\n",
    "    qrels,\n",
    "    names=[\"fastrank\",  \"random forest\", \"LambdaMart\", \"bm25\",'tf-idf'],\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Incorporating new features\n",
    "\n",
    "We didn't expect those approaches to do too well since queries might not reflect the content in the code-documents. But our bi-encoder model knows how to compare both! In Task 4's steps, you'll incorporate it's relevance predictions into the model as another feature.\n",
    "\n",
    "**Note**: For your course projects, if you use Pyterrier, this code should give you some idea of how to incorporate ranking features (or other information) that you've calculated from elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASZdKTPG675L"
   },
   "source": [
    "## Task 4.1 Loading in the precomputed relevance data\n",
    "\n",
    "Read in the dataframe with the bi-encoder's estimated relevance scores for each query-document pair (i.e., its cosine similarity), which we produced in Part 1. The length of the dataframe should be (number of unique query) * (number of unique documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d0</td>\n",
       "      <td>0.934156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0.938960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>d2</td>\n",
       "      <td>0.933673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>d3</td>\n",
       "      <td>0.897763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>d4</td>\n",
       "      <td>0.938280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid docno       sim\n",
       "0   0    d0  0.934156\n",
       "1   0    d1  0.938960\n",
       "2   0    d2  0.933673\n",
       "3   0    d3  0.897763\n",
       "4   0    d4  0.938280"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "prd = pd.read_csv('data/relevance_scores.csv').drop(columns = ['Unnamed: 0']).iloc[:, 2:].rename(columns = {\"Query_id\": \"qid\",'Doc_id':'docno'})\n",
    "prd['qid'] = prd['qid'].astype(str)\n",
    "prd['docno'] = 'd'+(prd['docno'].astype(str))\n",
    "\n",
    "prd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQx1n6BB7OMh"
   },
   "source": [
    "## Task 4.2: Adding new features (10 points)\n",
    "\n",
    "Once we have our bi-encoder estimates, we'll create a new pipeline that adds the score as a new feature. Recall that Pyterrier's [Pipeline](https://pyterrier.readthedocs.io/en/latest/pipeline_examples.html) is a transformation on a pandas `DataFrame` object. For us, that means we can write a function that operates on each row of the data frame and use pyterrier's [`apply`](https://pyterrier.readthedocs.io/en/latest/apply.html) (which is much like panda's [`apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)). Specifically, we'll write some code that for a given row with a document and query, looks up the precomputed relevance score.\n",
    "\n",
    "While there's many ways to do this, your steps should probably look something like this:\n",
    "* Create some data structure that can map a tuple of the query id and document id to the bi-encoder's relevance score\n",
    "* Write a function takes in a row from a `DataFrame` and uses the query id and document id in the row's columns to look up the bi-encoder's relevance.\n",
    "* Copy and extend your earlier pipeline by adding one new feature that uses pyterrier's `apply` function with your new function. Call this new pipeline `bienc_ltr_feats` so the later training functions can use it\n",
    "\n",
    "Once you have this pipeline in place, use the code below to retrain the models. \n",
    "\n",
    "Add the feature of cosine similarity between query and code embedding into the feaure pipeline. Train the three models and run the experiements again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Qvy1WjA-HdUl"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "sim_dict = {}\n",
    "for index, row in prd.iterrows():\n",
    "    sim_dict[(row.qid,row.docno)] = row.sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevance(row,sim_dict):\n",
    "    # row is the iterator of dataframe\n",
    "    return sim_dict[(row.qid,row.docno)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_ltr_feats = bm25 >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # tf-idf\n",
    "    tf_idf\n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    "    ** # bi-encoder's relevance\n",
    "    (pt.apply.doc_score(lambda row: find_relevance(row,sim_dict)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5CW7kxeH8_W",
    "outputId": "7725d639-065b-4b33-9251-867526691008"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "rf_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(train_topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHJYe-qNH_vy",
    "outputId": "ff924a7a-1b3c-400e-c75d-f8f1500f72f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.795\n",
      "   4|3               |    0.000|    0.798\n",
      "   0|3               |  -12.572|    0.298\n",
      "   0|3               |  -25.372|    0.303\n",
      "   0|3               |  -50.972|    0.306\n",
      "   0|3               | -102.172|    0.308\n",
      "   0|3               | -204.572|    0.309\n",
      "   0|3               | -409.372|    0.310\n",
      "   0|3               | -818.972|    0.311\n",
      "   0|3               |-1638.172|    0.311\n",
      "   0|3               |-3276.572|    0.311\n",
      "   0|3               |-6553.372|    0.311\n",
      "   0|3               |-13106.972|    0.311\n",
      "   0|3               |-26214.172|    0.311\n",
      "   0|3               |-52428.572|    0.311\n",
      "   0|3               |-104857.372|    0.311\n",
      "   0|3               |-209714.972|    0.311\n",
      "   0|3               |-838860.572|    0.311\n",
      "   4|0               |    0.373|    0.803\n",
      "   1|0               |    0.045|    0.795\n",
      "   4|0               |    0.473|    0.805\n",
      "   1|0               |    0.049|    0.795\n",
      "   1|0               |    0.058|    0.795\n",
      "   1|0               |    0.075|    0.796\n",
      "   0|2               |    0.000|    0.311\n",
      "   1|0               |    0.109|    0.797\n",
      "   1|0               |    0.177|    0.801\n",
      "   3|3               |    0.419|    0.575\n",
      "   2|3               |    0.173|    0.804\n",
      "   3|3               |    0.519|    0.596\n",
      "   1|0               |    0.586|    0.801\n",
      "   3|3               |    0.719|    0.624\n",
      "   2|3               |    0.273|    0.805\n",
      "   1|0               |    1.131|    0.802\n",
      "   2|3               |    0.473|    0.810\n",
      "   3|3               |    1.119|    0.658\n",
      "   2|3               |    0.873|    0.819\n",
      "   3|3               |    1.919|    0.690\n",
      "   2|3               |    1.673|    0.827\n",
      "   3|3               |    3.519|    0.718\n",
      "   2|3               |    3.273|    0.835\n",
      "   3|3               |    6.719|    0.735\n",
      "   2|3               |    6.473|    0.841\n",
      "   3|3               |   13.119|    0.739\n",
      "   3|3               |   25.919|    0.747\n",
      "   3|3               |   51.519|    0.751\n",
      "   3|3               |  102.719|    0.755\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   1|1               |    0.073|    0.802\n",
      "   1|1               |    0.056|    0.802\n",
      "   2|2               |    0.000|    0.842\n",
      "   0|2               |    0.000|    0.311\n",
      "   0|2               |    0.000|    0.311\n",
      "   0|2               |    0.000|    0.311\n",
      "   0|2               |    0.001|    0.311\n",
      "   0|2               |    0.001|    0.311\n",
      "   0|2               |    0.002|    0.311\n",
      "   0|2               |    0.005|    0.311\n",
      "   0|2               |    0.010|    0.312\n",
      "   1|1               |    0.091|    0.802\n",
      "   0|2               |    0.020|    0.313\n",
      "   1|1               |    0.099|    0.802\n",
      "   1|1               |    0.116|    0.802\n",
      "   0|2               |    0.039|    0.315\n",
      "   1|1               |    0.151|    0.802\n",
      "   0|2               |    0.079|    0.320\n",
      "   0|2               |    0.157|    0.332\n",
      "   1|1               |    0.358|    0.802\n",
      "   1|1               |    0.634|    0.803\n",
      "   0|2               |    0.315|    0.368\n",
      "   0|2               |    0.630|    0.443\n",
      "   1|1               |    8.917|    0.803\n",
      "   0|0               |    0.000|    0.443\n",
      "   1|1               |   35.423|    0.803\n",
      "   1|1               |   70.763|    0.803\n",
      "   2|0               |    0.085|    0.843\n",
      "   3|1               |    0.004|    0.758\n",
      "   3|1               |    0.005|    0.762\n",
      "   3|1               |    0.007|    0.767\n",
      "   3|1               |    0.011|    0.776\n",
      "   3|1               |    0.020|    0.792\n",
      "   3|1               |    0.038|    0.809\n",
      "   3|1               |    0.073|    0.830\n",
      "   3|1               |    0.144|    0.840\n",
      "   1|2               |   -0.127|    0.804\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.526|    0.805\n",
      "   1|2               |   -1.058|    0.810\n",
      "   0|0               |   -0.000|    0.443\n",
      "   2|1               |   -0.031|    0.844\n",
      "   0|0               |    0.000|    0.443\n",
      "   0|0               |    0.000|    0.443\n",
      "   0|0               |    0.000|    0.443\n",
      "   3|2               |    0.000|    0.840\n",
      "   0|0               |    0.000|    0.443\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.443\n",
      "   0|0               |    0.000|    0.443\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.443\n",
      "   4|3               |    0.000|    0.806\n",
      "   3|2               |   -0.007|    0.840\n",
      "   0|0               |    0.000|    0.444\n",
      "   0|0               |    0.000|    0.444\n",
      "   3|2               |   -0.012|    0.841\n",
      "   3|2               |   -0.023|    0.841\n",
      "   0|0               |    0.000|    0.445\n",
      "   3|2               |   -0.044|    0.843\n",
      "   0|0               |    0.001|    0.447\n",
      "   0|0               |    0.002|    0.453\n",
      "   0|0               |    0.004|    0.462\n",
      "   0|0               |    0.008|    0.486\n",
      "   0|0               |    0.015|    0.521\n",
      "   0|0               |    0.030|    0.568\n",
      "   0|0               |    0.061|    0.641\n",
      "   0|0               |    0.121|    0.712\n",
      "   0|0               |    0.243|    0.757\n",
      "   2|1               |   -0.028|    0.845\n",
      "   0|1               |   -0.000|    0.757\n",
      "   3|0               |   -0.001|    0.843\n",
      "   1|3               |    0.050|    0.812\n",
      "   1|3               |    0.150|    0.821\n",
      "   4|3               |    0.050|    0.809\n",
      "   1|3               |    0.350|    0.826\n",
      "   4|3               |    0.150|    0.814\n",
      "   1|3               |    0.750|    0.830\n",
      "   4|3               |    0.350|    0.820\n",
      "   1|3               |    1.550|    0.844\n",
      "   4|3               |    0.750|    0.827\n",
      "   4|3               |    1.550|    0.843\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|0               |   -0.001|    0.844\n",
      "   3|0               |   -0.001|    0.844\n",
      "   3|0               |    0.003|    0.845\n",
      "   1|2               |   -0.252|    0.844\n",
      "   0|1               |    0.000|    0.757\n",
      "   4|1               |   -0.088|    0.843\n",
      "   0|1               |    0.000|    0.757\n",
      "   4|1               |   -0.096|    0.844\n",
      "   4|1               |   -0.113|    0.844\n",
      "   0|1               |    0.001|    0.757\n",
      "   0|1               |    0.001|    0.757\n",
      "   0|1               |    0.002|    0.757\n",
      "   0|1               |    0.005|    0.758\n",
      "   0|1               |    0.010|    0.759\n",
      "   0|1               |    0.019|    0.760\n",
      "   0|1               |    0.038|    0.761\n",
      "   0|1               |    0.076|    0.767\n",
      "   0|1               |    0.153|    0.772\n",
      "   0|1               |    0.306|    0.778\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.200|    0.780\n",
      "   0|0               |    0.300|    0.783\n",
      "   0|0               |    0.500|    0.792\n",
      "   0|0               |    0.900|    0.795\n",
      "   0|0               |    1.700|    0.797\n",
      "   0|0               |    3.300|    0.798\n",
      "   0|0               |    6.500|    0.801\n",
      "   0|0               |   12.900|    0.801\n",
      "   3|3               |    0.885|    0.845\n",
      "   3|0               |    0.002|    0.845\n",
      "   3|0               |    0.002|    0.845\n",
      "   0|1               |    0.234|    0.801\n",
      "   2|2               |   -0.050|    0.847\n",
      "   0|1               |    0.888|    0.802\n",
      "   0|1               |    1.759|    0.803\n",
      "   0|1               |   13.962|    0.803\n",
      "   0|1               |   27.908|    0.803\n",
      "   0|1               |  111.582|    0.803\n",
      "   0|3               |   -0.000|    0.803\n",
      "   1|0               |    0.001|    0.844\n",
      "   1|0               |    0.001|    0.844\n",
      "   3|0               |    0.006|    0.846\n",
      "   1|0               |    0.000|    0.845\n",
      "   1|0               |   -0.007|    0.846\n",
      "   1|0               |   -0.016|    0.847\n",
      "   3|2               |   -0.042|    0.846\n",
      "   3|2               |   -0.046|    0.847\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|2               |   -0.054|    0.847\n",
      "   3|2               |   -0.069|    0.848\n",
      "   0|3               |    0.003|    0.803\n",
      "   0|3               |    0.006|    0.803\n",
      "   0|3               |    0.012|    0.804\n",
      "   0|3               |    0.025|    0.804\n",
      "   0|3               |    0.050|    0.804\n",
      "   0|3               |    0.100|    0.805\n",
      "   0|3               |    0.200|    0.807\n",
      "   2|1               |   -0.018|    0.847\n",
      "   0|3               |    0.400|    0.809\n",
      "   0|3               |    0.800|    0.815\n",
      "   0|3               |    1.601|    0.823\n",
      "   0|3               |    3.202|    0.835\n",
      "   0|3               |    6.404|    0.844\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|2               |    0.000|    0.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|2               |   -0.000|    0.844\n",
      "   0|2               |   -0.000|    0.844\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|2               |   -0.002|    0.844\n",
      "   0|2               |   -0.004|    0.844\n",
      "   0|2               |   -0.034|    0.844\n",
      "   0|2               |   -0.068|    0.845\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.845\n",
      "   0|0               |    0.001|    0.845\n",
      "   0|0               |   -0.001|    0.846\n",
      "   0|0               |   -0.002|    0.846\n",
      "   4|3               |    0.541|    0.844\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |    0.641|    0.845\n",
      "   4|3               |    0.741|    0.847\n",
      "   4|1               |   -0.110|    0.847\n",
      "   3|2               |   -0.071|    0.848\n",
      "   2|2               |   -0.065|    0.847\n",
      "   4|1               |   -0.081|    0.848\n",
      "   2|2               |   -0.046|    0.848\n",
      "   2|2               |   -0.041|    0.848\n",
      "   1|0               |   -0.015|    0.847\n",
      "   0|2               |   -0.067|    0.847\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|2               |   -0.070|    0.847\n",
      "   2|2               |   -0.039|    0.848\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    }
   ],
   "source": [
    "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "params = train_request.params\n",
    "params.init_random = True\n",
    "params.normalize = True\n",
    "params.seed = 1234567\n",
    "ca_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "ca_pipe.fit(train_topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ziwEUjoIZJL",
    "outputId": "f58f6cdc-5a82-4b44-c7b0-d5a1e2bc979a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "lmart_x_pipe.fit(train_topics, qrels, valid_topics, qrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3 Re-run the experiment here using the new features! (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.818955</td>\n",
       "      <td>0.855715</td>\n",
       "      <td>0.790695</td>\n",
       "      <td>30.655216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0.823676</td>\n",
       "      <td>0.728540</td>\n",
       "      <td>33.603868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.685549</td>\n",
       "      <td>0.727322</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>22.535864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.778419</td>\n",
       "      <td>0.825697</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>5.761557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map      ndcg  ndcg_cut_10        mrt\n",
       "0       fastrank  0.818955  0.855715     0.790695  30.655216\n",
       "1  random forest  0.758528  0.823676     0.728540  33.603868\n",
       "2     LambdaMart  0.685549  0.727322     0.614833  22.535864\n",
       "3           bm25  0.778419  0.825697     0.744078   5.761557"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "pt.Experiment(\n",
    "    [ca_pipe, rf_pipe, lmart_x_pipe,bm25], \n",
    "    test_topics,\n",
    "    qrels,\n",
    "    names=[\"fastrank\",  \"random forest\", \"LambdaMart\", \"bm25\"],\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Optional_: Evaluating the different models (20 points total; this is part 2)\n",
    "\n",
    "How much training does the model actually need to recognize relevance? Would one epoch be enough? What if we did 10? or 100? (100 might be too many for Great Lakes limits...). In this **optional part**, we'll describe a series of steps you can take to explore this part!\n",
    " \n",
    "The instructions in Part 1 had you update that notebook to save the model after each epoch and then generate relevance predictions for each, saving those to a file. In Part 2, we'll load those files and compare the performance:\n",
    " \n",
    "Here's what you need to do:\n",
    "* Using the code from the blocks above, create new version of the test data DataFrame that have predictions from each trained bi-encoder model. (i.e., you should have predictions from the model trained on one epoch worth of data, predictions from the model trained on two epochs, etc.)\n",
    "* Retrain each L2R model using each of these new features, using just one feature at a time. This should give you (number of L2R models) * (number of different-epoch-trained-biencoder-models) worth of results.\n",
    "* Create a line plot where\n",
    "  * the x-axis is the number of epochs the bi-encoder model was trained\n",
    "  * the y-axis is NDCG_cut_10\n",
    "  * there are different lines for each L2R model (with different colors/hues for each model)\n",
    " \n",
    "This plot should show you how much the bi-encoder's training time influences the scores. Compare that with the F1 performance plot you produced for Part 1. Does increasing F1 performance lead to increasing NDCG@10? How many epochs do you think you need to train to maximize performance?\n",
    "\n",
    "**TODO:** For full credit, submit a separate doc/pdf with the plots from Parts 1 and 2 and a short paragraph describing your observations on the performance (see the questions above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|3               |    0.000|    0.801\n",
      "   3|3               |    0.000|    0.364\n",
      "   4|3               |    0.000|    0.798\n",
      "   2|3               |    0.073|    0.801\n",
      "   2|3               |   -0.227|    0.801\n",
      "   0|3               |   -6.172|    0.297\n",
      "   0|3               |  -12.572|    0.297\n",
      "   0|3               |  -25.372|    0.299\n",
      "   0|3               |  -50.972|    0.301\n",
      "   0|3               | -102.172|    0.307\n",
      "   0|3               | -204.572|    0.321\n",
      "   0|3               | -409.372|    0.348\n",
      "   0|3               | -818.972|    0.375\n",
      "   0|3               |-1638.172|    0.397\n",
      "   0|3               |-3276.572|    0.406\n",
      "   0|3               |-6553.372|    0.412\n",
      "   0|3               |-13106.972|    0.415\n",
      "   0|3               |-26214.172|    0.416\n",
      "   0|3               |-52428.572|    0.417\n",
      "   4|0               |    0.373|    0.803\n",
      "   0|3               |-104857.372|    0.417\n",
      "   4|0               |    0.473|    0.805\n",
      "   0|3               |-209714.972|    0.417\n",
      "   0|3               |-419430.172|    0.417\n",
      "   0|3               |-838860.572|    0.418\n",
      "   0|3               |-1677721.372|    0.418\n",
      "   1|3               |   -0.085|    0.795\n",
      "   3|1               |    0.501|    0.659\n",
      "   3|1               |    0.601|    0.808\n",
      "   3|1               |    0.801|    0.810\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   2|2               |    0.058|    0.801\n",
      "   0|2               |    0.000|    0.418\n",
      "   3|2               |   -0.378|    0.811\n",
      "   2|2               |   -0.325|    0.804\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.418\n",
      "   0|2               |    0.000|    0.419\n",
      "   0|2               |    0.000|    0.420\n",
      "   0|2               |    0.001|    0.423\n",
      "   0|2               |    0.001|    0.432\n",
      "   0|2               |    0.002|    0.448\n",
      "   1|0               |    0.041|    0.795\n",
      "   1|0               |    0.045|    0.796\n",
      "   0|2               |    0.005|    0.490\n",
      "   2|0               |    0.374|    0.805\n",
      "   1|0               |    0.052|    0.796\n",
      "   0|2               |    0.010|    0.568\n",
      "   2|0               |    0.274|    0.807\n",
      "   1|0               |    0.068|    0.796\n",
      "   0|2               |    0.020|    0.665\n",
      "   0|2               |    0.039|    0.701\n",
      "   1|0               |    0.099|    0.797\n",
      "   0|2               |    0.079|    0.705\n",
      "   1|0               |    0.161|    0.801\n",
      "   1|0               |    0.534|    0.801\n",
      "   1|0               |    1.031|    0.802\n",
      "   0|0               |    0.000|    0.705\n",
      "   1|1               |    0.070|    0.802\n",
      "   1|1               |    0.054|    0.802\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.000|    0.705\n",
      "   4|3               |   -0.050|    0.807\n",
      "   4|3               |   -0.150|    0.807\n",
      "   0|0               |    0.000|    0.705\n",
      "   0|0               |    0.000|    0.705\n",
      "   0|0               |    0.000|    0.705\n",
      "   1|1               |    0.087|    0.802\n",
      "   0|0               |    0.000|    0.706\n",
      "   1|1               |    0.111|    0.802\n",
      "   0|0               |    0.000|    0.707\n",
      "   1|1               |    0.144|    0.802\n",
      "   1|1               |    0.342|    0.802\n",
      "   1|1               |    0.606|    0.803\n",
      "   0|0               |    0.000|    0.712\n",
      "   0|0               |    0.001|    0.725\n",
      "   1|1               |    8.519|    0.803\n",
      "   0|0               |    0.001|    0.743\n",
      "   0|0               |    0.003|    0.765\n",
      "   0|0               |    0.006|    0.782\n",
      "   1|1               |   33.841|    0.803\n",
      "   0|0               |    0.011|    0.789\n",
      "   1|1               |   67.603|    0.803\n",
      "   0|0               |    0.023|    0.792\n",
      "   0|0               |    0.046|    0.796\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.092|    0.798\n",
      "   0|0               |    0.183|    0.799\n",
      "   0|1               |   -0.000|    0.799\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |   -0.050|    0.811\n",
      "   1|2               |   -0.127|    0.804\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.526|    0.805\n",
      "   0|1               |   -0.000|    0.799\n",
      "   1|2               |   -1.057|    0.810\n",
      "   0|1               |   -0.001|    0.799\n",
      "   0|1               |   -0.002|    0.799\n",
      "   0|1               |   -0.004|    0.799\n",
      "   0|1               |   -0.008|    0.799\n",
      "   2|3               |   -0.041|    0.807\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |   -0.000|    0.810\n",
      "   1|3               |   -0.033|    0.810\n",
      "   1|3               |   -0.261|    0.810\n",
      "   0|1               |    0.030|    0.801\n",
      "   0|1               |    0.061|    0.801\n",
      "   0|1               |    0.121|    0.802\n",
      "   0|1               |    0.242|    0.802\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.175|    0.802\n",
      "   1|2               |   -0.459|    0.811\n",
      "   0|1               |    0.136|    0.802\n",
      "   3|2               |   -0.363|    0.814\n",
      "   0|1               |    0.336|    0.803\n",
      "   0|1               |    0.536|    0.803\n",
      "   0|1               |    0.936|    0.803\n",
      "   0|1               |    1.736|    0.803\n",
      "   0|1               |    3.336|    0.803\n",
      "   0|1               |    6.536|    0.803\n",
      "   0|1               |   25.736|    0.803\n",
      "   0|3               |   -0.024|    0.803\n",
      "   0|3               |   -0.026|    0.803\n",
      "   0|3               |   -0.094|    0.803\n",
      "   0|3               |  -37.076|    0.806\n",
      "   0|2               |   -0.000|    0.806\n",
      "   0|2               |   -0.001|    0.806\n",
      "   0|2               |   -0.001|    0.806\n",
      "   0|2               |   -0.002|    0.806\n",
      "   0|2               |   -0.005|    0.806\n",
      "   0|2               |   -0.038|    0.806\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|0               |    0.000|    0.811\n",
      "   1|0               |   -0.002|    0.811\n",
      "   1|0               |   -0.015|    0.812\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |   -0.043|    0.814\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.813\n",
      "   1|3               |   -0.345|    0.813\n",
      "   1|3               |   -0.545|    0.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|0               |    0.000|    0.806\n",
      "   0|0               |    0.000|    0.806\n",
      "   0|0               |    0.000|    0.806\n",
      "   0|0               |    0.001|    0.807\n",
      "   0|2               |   -0.039|    0.807\n",
      "   0|2               |   -0.035|    0.807\n",
      "   1|0               |   -0.010|    0.813\n",
      "   1|0               |   -0.009|    0.813\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |    0.000|    0.798\n",
      "   1|3               |    0.000|    0.795\n",
      "   3|3               |    0.219|    0.368\n",
      "   0|3               |   -2.972|    0.296\n",
      "   0|3               |   -6.172|    0.296\n",
      "   0|3               |  -12.572|    0.297\n",
      "   0|3               |  -25.372|    0.299\n",
      "   0|3               |  -50.972|    0.304\n",
      "   0|3               | -102.172|    0.310\n",
      "   3|3               |  -50.781|    0.372\n",
      "   3|3               | -101.981|    0.376\n",
      "   0|3               | -204.572|    0.323\n",
      "   3|3               | -204.381|    0.378\n",
      "   0|3               | -409.372|    0.349\n",
      "   3|3               | -409.181|    0.379\n",
      "   0|3               | -818.972|    0.363\n",
      "   3|3               | -818.781|    0.380\n",
      "   0|3               |-1638.172|    0.371\n",
      "   3|3               |-1637.981|    0.380\n",
      "   0|3               |-3276.572|    0.375\n",
      "   3|3               |-3276.381|    0.380\n",
      "   0|3               |-6553.372|    0.378\n",
      "   0|3               |-13106.972|    0.379\n",
      "   3|3               |-6553.181|    0.380\n",
      "   3|3               |-13106.781|    0.382\n",
      "   0|3               |-26214.172|    0.379\n",
      "   3|3               |-26213.981|    0.382\n",
      "   0|3               |-52428.572|    0.380\n",
      "   3|3               |-52428.381|    0.382\n",
      "   4|0               |    0.373|    0.803\n",
      "   0|3               |-104857.372|    0.380\n",
      "   4|0               |    0.473|    0.805\n",
      "   0|3               |-209714.972|    0.380\n",
      "   0|3               |-419430.172|    0.380\n",
      "   3|3               |-209714.781|    0.382\n",
      "   0|3               |-838860.572|    0.382\n",
      "   1|3               |    0.015|    0.795\n",
      "   3|3               |-838860.381|    0.382\n",
      "   0|3               |-1677721.372|    0.382\n",
      "   1|3               |    0.215|    0.795\n",
      "   0|2               |    0.000|    0.382\n",
      "   2|3               |    0.173|    0.802\n",
      "   0|2               |    0.000|    0.382\n",
      "   2|3               |    0.273|    0.802\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   0|2               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   2|2               |   -0.312|    0.805\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   2|2               |   -0.686|    0.805\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.382\n",
      "   3|1               |    0.000|    0.382\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   0|2               |    0.000|    0.384\n",
      "   3|1               |    0.000|    0.383\n",
      "   0|2               |    0.001|    0.386\n",
      "   3|1               |    0.000|    0.384\n",
      "   3|1               |    0.000|    0.387\n",
      "   0|2               |    0.001|    0.390\n",
      "   3|1               |    0.000|    0.391\n",
      "   0|2               |    0.002|    0.397\n",
      "   3|1               |    0.001|    0.399\n",
      "   3|1               |    0.001|    0.424\n",
      "   0|2               |    0.005|    0.416\n",
      "   1|0               |    0.046|    0.796\n",
      "   3|1               |    0.002|    0.473\n",
      "   0|2               |    0.010|    0.459\n",
      "   3|1               |    0.004|    0.581\n",
      "   3|1               |    0.009|    0.668\n",
      "   1|0               |    0.142|    0.798\n",
      "   0|2               |    0.020|    0.518\n",
      "   1|0               |    0.251|    0.800\n",
      "   3|1               |    0.018|    0.735\n",
      "   0|2               |    0.039|    0.594\n",
      "   1|0               |    0.469|    0.802\n",
      "   3|1               |    0.036|    0.777\n",
      "   1|0               |    0.906|    0.802\n",
      "   0|2               |    0.079|    0.622\n",
      "   3|1               |    0.071|    0.789\n",
      "   0|2               |    0.157|    0.667\n",
      "   3|1               |    0.142|    0.795\n",
      "   0|2               |    0.315|    0.668\n",
      "   3|1               |    0.284|    0.799\n",
      "   3|1               |    0.569|    0.802\n",
      "   1|1               |    0.066|    0.802\n",
      "   1|1               |    0.050|    0.802\n",
      "   1|1               |   -0.166|    0.802\n",
      "   3|2               |   -0.000|    0.802\n",
      "   2|0               |    0.366|    0.807\n",
      "   3|2               |   -0.002|    0.802\n",
      "   3|2               |   -0.004|    0.802\n",
      "   3|2               |   -0.015|    0.802\n",
      "   3|2               |   -0.124|    0.802\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|2               |   -0.247|    0.805\n",
      "   0|0               |   -0.000|    0.668\n",
      "   1|1               |    0.104|    0.802\n",
      "   0|0               |    0.000|    0.668\n",
      "   1|1               |    0.320|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   1|1               |    0.567|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   0|0               |    0.000|    0.668\n",
      "   0|0               |    0.000|    0.668\n",
      "   0|0               |    0.000|    0.668\n",
      "   0|0               |    0.000|    0.668\n",
      "   1|1               |    7.967|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   1|1               |   31.650|    0.803\n",
      "   0|0               |    0.000|    0.670\n",
      "   0|0               |    0.000|    0.671\n",
      "   1|1               |   63.227|    0.803\n",
      "   0|0               |    0.001|    0.677\n",
      "   3|0               |   -0.010|    0.805\n",
      "   0|0               |    0.001|    0.685\n",
      "   0|0               |    0.002|    0.709\n",
      "   0|0               |    0.005|    0.727\n",
      "   0|0               |    0.009|    0.750\n",
      "   0|0               |    0.019|    0.774\n",
      "   0|0               |    0.038|    0.780\n",
      "   0|0               |    0.075|    0.787\n",
      "   0|0               |    0.150|    0.797\n",
      "   0|1               |    0.000|    0.797\n",
      "   4|3               |    0.050|    0.807\n",
      "   1|2               |   -0.127|    0.804\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.525|    0.805\n",
      "   1|2               |   -1.056|    0.810\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.000|    0.806\n",
      "   3|0               |    0.000|    0.806\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|1               |   -0.003|    0.797\n",
      "   1|3               |    0.000|    0.810\n",
      "   1|3               |   -0.000|    0.810\n",
      "   3|0               |   -0.081|    0.807\n",
      "   1|3               |   -0.002|    0.810\n",
      "   3|0               |   -0.144|    0.808\n",
      "   1|3               |   -0.004|    0.810\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |   -0.165|    0.811\n",
      "   3|2               |   -0.404|    0.810\n",
      "   0|1               |    0.013|    0.797\n",
      "   0|1               |    0.051|    0.798\n",
      "   0|1               |    0.102|    0.800\n",
      "   0|1               |    0.205|    0.801\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|3               |    0.189|    0.807\n",
      "   1|3               |    0.084|    0.811\n",
      "   1|3               |    0.167|    0.811\n",
      "   0|0               |    0.159|    0.801\n",
      "   0|0               |    0.259|    0.802\n",
      "   1|2               |   -0.492|    0.811\n",
      "   0|1               |    0.198|    0.802\n",
      "   0|1               |    0.298|    0.802\n",
      "   0|1               |    0.898|    0.802\n",
      "   0|1               |    1.698|    0.803\n",
      "   0|1               |    6.498|    0.803\n",
      "   0|1               |   12.898|    0.803\n",
      "   0|1               |   25.698|    0.803\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|3               |   -0.019|    0.803\n",
      "   3|3               |    0.050|    0.810\n",
      "   3|3               |    0.350|    0.813\n",
      "   0|3               |   -0.015|    0.803\n",
      "   0|3               |    0.441|    0.804\n",
      "   1|0               |    0.000|    0.811\n",
      "   1|0               |    0.002|    0.811\n",
      "   1|0               |   -0.016|    0.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|2               |    0.000|    0.804\n",
      "   0|2               |   -0.009|    0.804\n",
      "   0|2               |   -0.047|    0.804\n",
      "   0|2               |   -0.098|    0.804\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|2               |   -0.199|    0.804\n",
      "   0|2               |   -0.403|    0.806\n",
      "   1|3               |    0.084|    0.813\n",
      "   0|2               |   -0.810|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.811\n",
      "   0|0               |    0.003|    0.811\n",
      "   0|0               |   -0.002|    0.811\n",
      "   0|0               |   -0.007|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.309|    0.813\n",
      "   1|0               |   -0.018|    0.813\n",
      "   1|0               |   -0.016|    0.813\n",
      "   1|0               |   -0.014|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.007|    0.813\n",
      "   0|0               |   -0.007|    0.813\n",
      "   0|0               |   -0.006|    0.813\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.795\n",
      "   4|3               |    0.000|    0.798\n",
      "   3|3               |    0.219|    0.369\n",
      "   0|3               |   -2.972|    0.296\n",
      "   0|3               |   -6.172|    0.296\n",
      "   0|3               |  -12.572|    0.297\n",
      "   0|3               |  -25.372|    0.299\n",
      "   0|3               |  -50.972|    0.305\n",
      "   3|3               |  -50.781|    0.374\n",
      "   0|3               | -102.172|    0.311\n",
      "   0|3               | -204.572|    0.327\n",
      "   3|3               | -101.981|    0.380\n",
      "   0|3               | -409.372|    0.355\n",
      "   3|3               | -204.381|    0.384\n",
      "   0|3               | -818.972|    0.367\n",
      "   3|3               | -409.181|    0.385\n",
      "   0|3               |-1638.172|    0.375\n",
      "   3|3               | -818.781|    0.385\n",
      "   0|3               |-3276.572|    0.382\n",
      "   3|3               |-1637.981|    0.386\n",
      "   0|3               |-6553.372|    0.384\n",
      "   3|3               |-3276.381|    0.386\n",
      "   3|3               |-6553.181|    0.386\n",
      "   0|3               |-13106.972|    0.385\n",
      "   3|3               |-13106.781|    0.386\n",
      "   0|3               |-26214.172|    0.385\n",
      "   0|3               |-52428.572|    0.385\n",
      "   0|3               |-104857.372|    0.385\n",
      "   0|3               |-209714.972|    0.386\n",
      "   4|0               |    0.373|    0.803\n",
      "   0|3               |-419430.172|    0.386\n",
      "   4|0               |    0.473|    0.805\n",
      "   0|3               |-838860.572|    0.386\n",
      "   0|3               |-1677721.372|    0.386\n",
      "   2|3               |    0.173|    0.802\n",
      "   1|3               |    0.015|    0.795\n",
      "   1|3               |    0.215|    0.795\n",
      "   0|2               |   -0.000|    0.386\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   3|1               |    0.000|    0.386\n",
      "   3|1               |    0.000|    0.386\n",
      "   2|2               |    0.061|    0.802\n",
      "   3|1               |    0.000|    0.386\n",
      "   3|1               |    0.000|    0.386\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.000|    0.388\n",
      "   3|1               |    0.000|    0.389\n",
      "   3|1               |    0.000|    0.395\n",
      "   2|2               |   -0.342|    0.805\n",
      "   3|1               |    0.000|    0.399\n",
      "   2|2               |   -0.751|    0.805\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.001|    0.405\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.001|    0.422\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.002|    0.470\n",
      "   0|2               |    0.000|    0.386\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.004|    0.555\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.009|    0.658\n",
      "   3|1               |    0.018|    0.729\n",
      "   0|2               |    0.000|    0.393\n",
      "   3|1               |    0.036|    0.775\n",
      "   0|2               |    0.001|    0.394\n",
      "   3|1               |    0.071|    0.789\n",
      "   0|2               |    0.001|    0.396\n",
      "   3|1               |    0.142|    0.794\n",
      "   3|1               |    0.284|    0.799\n",
      "   0|2               |    0.002|    0.402\n",
      "   3|1               |    0.569|    0.802\n",
      "   1|0               |    0.036|    0.795\n",
      "   0|2               |    0.005|    0.414\n",
      "   3|1               |    1.138|    0.802\n",
      "   1|0               |    0.039|    0.795\n",
      "   3|1               |    2.276|    0.803\n",
      "   0|2               |    0.010|    0.440\n",
      "   1|0               |    0.046|    0.796\n",
      "   3|1               |    4.551|    0.803\n",
      "   0|2               |    0.020|    0.512\n",
      "   3|1               |    9.103|    0.803\n",
      "   0|2               |    0.039|    0.586\n",
      "   3|1               |   18.205|    0.803\n",
      "   1|0               |    0.087|    0.797\n",
      "   0|2               |    0.079|    0.618\n",
      "   1|0               |    0.142|    0.798\n",
      "   3|1               |   36.410|    0.803\n",
      "   1|0               |    0.251|    0.800\n",
      "   0|2               |    0.157|    0.667\n",
      "   1|0               |    0.469|    0.802\n",
      "   0|2               |    0.315|    0.667\n",
      "   1|0               |    0.906|    0.802\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|2               |   -0.000|    0.803\n",
      "   3|2               |   -0.010|    0.803\n",
      "   0|0               |   -0.000|    0.667\n",
      "   1|1               |    0.050|    0.802\n",
      "   2|0               |    0.384|    0.807\n",
      "   1|1               |   -0.166|    0.802\n",
      "   3|2               |   -0.166|    0.804\n",
      "   3|2               |   -0.664|    0.806\n",
      "   3|0               |    0.000|    0.806\n",
      "   3|0               |   -0.000|    0.806\n",
      "   3|0               |   -0.000|    0.806\n",
      "   3|0               |   -0.000|    0.806\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|0               |   -0.002|    0.806\n",
      "   3|0               |   -0.005|    0.806\n",
      "   3|0               |   -0.010|    0.806\n",
      "   0|0               |    0.000|    0.667\n",
      "   1|1               |    0.135|    0.802\n",
      "   0|0               |    0.000|    0.668\n",
      "   1|1               |    0.320|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   3|0               |   -0.078|    0.807\n",
      "   1|1               |    0.567|    0.803\n",
      "   3|0               |   -0.157|    0.813\n",
      "   0|0               |    0.000|    0.668\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.669\n",
      "   0|0               |    0.000|    0.671\n",
      "   0|0               |    0.001|    0.675\n",
      "   1|1               |    7.967|    0.803\n",
      "   0|0               |    0.001|    0.684\n",
      "   0|0               |    0.002|    0.708\n",
      "   1|1               |   31.650|    0.803\n",
      "   0|0               |    0.005|    0.728\n",
      "   1|1               |   63.227|    0.803\n",
      "   0|0               |    0.009|    0.749\n",
      "   0|0               |    0.019|    0.773\n",
      "   0|0               |    0.038|    0.779\n",
      "   0|0               |    0.075|    0.787\n",
      "   0|0               |    0.150|    0.797\n",
      "   0|1               |    0.000|    0.797\n",
      "   0|1               |   -0.000|    0.797\n",
      "   4|3               |    0.050|    0.807\n",
      "   1|2               |   -0.127|    0.804\n",
      "   0|1               |   -0.000|    0.797\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.525|    0.805\n",
      "   1|2               |   -1.056|    0.810\n",
      "   0|1               |   -0.003|    0.797\n",
      "   0|1               |   -0.006|    0.797\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |   -0.000|    0.810\n",
      "   1|3               |   -0.002|    0.810\n",
      "   2|3               |    0.088|    0.807\n",
      "   1|3               |   -0.004|    0.810\n",
      "   1|3               |   -0.165|    0.811\n",
      "   0|1               |    0.026|    0.797\n",
      "   0|1               |    0.051|    0.798\n",
      "   0|1               |    0.102|    0.798\n",
      "   0|1               |    0.205|    0.801\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|3               |    0.097|    0.807\n",
      "   2|3               |    0.125|    0.807\n",
      "   2|3               |    0.162|    0.807\n",
      "   1|3               |    0.084|    0.811\n",
      "   1|3               |    0.167|    0.811\n",
      "   0|0               |    0.159|    0.801\n",
      "   0|0               |    0.259|    0.802\n",
      "   1|2               |   -0.492|    0.811\n",
      "   3|2               |   -0.395|    0.815\n",
      "   0|1               |    0.198|    0.802\n",
      "   0|1               |    0.298|    0.802\n",
      "   0|1               |    1.698|    0.803\n",
      "   0|1               |    6.498|    0.803\n",
      "   0|1               |   12.898|    0.803\n",
      "   0|1               |   25.698|    0.803\n",
      "   0|3               |   -0.021|    0.803\n",
      "   1|1               |    0.443|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |   -0.014|    0.815\n",
      "   0|3               |   -0.017|    0.803\n",
      "   0|3               |   -0.012|    0.803\n",
      "   0|3               |   -0.004|    0.803\n",
      "   0|3               |    0.096|    0.803\n",
      "   3|3               |   -0.013|    0.815\n",
      "   3|3               |   -0.011|    0.815\n",
      "   3|3               |   -0.009|    0.815\n",
      "   3|3               |   -0.003|    0.815\n",
      "   0|2               |    0.005|    0.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|2               |   -0.129|    0.804\n",
      "   0|2               |   -0.532|    0.806\n",
      "   0|2               |   -1.069|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.004|    0.811\n",
      "   0|0               |   -0.002|    0.811\n",
      "   0|0               |   -0.020|    0.813\n",
      "   0|3               |    0.045|    0.813\n",
      "   0|3               |    0.057|    0.813\n",
      "   0|3               |    0.074|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.020|    0.813\n",
      "   0|3               |    0.076|    0.813\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "[+] Random restart #2/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.795\n",
      "   4|3               |    0.000|    0.798\n",
      "   3|3               |    0.219|    0.369\n",
      "   0|3               |   -2.972|    0.296\n",
      "   0|3               |   -6.172|    0.296\n",
      "   0|3               |  -12.572|    0.297\n",
      "   0|3               |  -25.372|    0.299\n",
      "   0|3               |  -50.972|    0.305\n",
      "   3|3               |  -50.781|    0.374\n",
      "   0|3               | -102.172|    0.311\n",
      "   3|3               | -101.981|    0.378\n",
      "   0|3               | -204.572|    0.327\n",
      "   3|3               | -204.381|    0.382\n",
      "   0|3               | -409.372|    0.355\n",
      "   3|3               | -409.181|    0.382\n",
      "   0|3               | -818.972|    0.368\n",
      "   3|3               | -818.781|    0.383\n",
      "   0|3               |-1638.172|    0.374\n",
      "   3|3               |-1637.981|    0.383\n",
      "   0|3               |-3276.572|    0.379\n",
      "   3|3               |-3276.381|    0.383\n",
      "   0|3               |-6553.372|    0.381\n",
      "   3|3               |-6553.181|    0.383\n",
      "   0|3               |-13106.972|    0.382\n",
      "   3|3               |-13106.781|    0.383\n",
      "   0|3               |-26214.172|    0.383\n",
      "   3|3               |-26213.981|    0.383\n",
      "   0|3               |-52428.572|    0.383\n",
      "   3|3               |-52428.381|    0.383\n",
      "   0|3               |-104857.372|    0.383\n",
      "   3|3               |-104857.181|    0.383\n",
      "   0|3               |-209714.972|    0.383\n",
      "   4|0               |    0.373|    0.803\n",
      "   3|3               |-209714.781|    0.383\n",
      "   0|3               |-419430.172|    0.383\n",
      "   4|0               |    0.473|    0.805\n",
      "   3|3               |-419429.981|    0.383\n",
      "   0|3               |-838860.572|    0.383\n",
      "   2|3               |    0.173|    0.802\n",
      "   2|3               |    0.273|    0.802\n",
      "   0|3               |-1677721.372|    0.383\n",
      "   1|3               |    0.015|    0.795\n",
      "   1|3               |    0.215|    0.795\n",
      "   0|2               |    0.000|    0.383\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   2|2               |   -0.125|    0.802\n",
      "   2|2               |   -0.312|    0.805\n",
      "   3|1               |    0.000|    0.383\n",
      "   2|2               |   -0.686|    0.805\n",
      "   3|1               |    0.000|    0.383\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.384\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.386\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.386\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.387\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.394\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.001|    0.405\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.001|    0.420\n",
      "   0|2               |    0.000|    0.384\n",
      "   3|1               |    0.002|    0.465\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.004|    0.555\n",
      "   0|2               |    0.001|    0.387\n",
      "   3|1               |    0.009|    0.662\n",
      "   0|2               |    0.001|    0.396\n",
      "   3|1               |    0.018|    0.730\n",
      "   0|2               |    0.002|    0.402\n",
      "   3|1               |    0.036|    0.773\n",
      "   3|1               |    0.071|    0.788\n",
      "   1|0               |    0.036|    0.795\n",
      "   0|2               |    0.005|    0.414\n",
      "   1|0               |    0.039|    0.796\n",
      "   3|1               |    0.142|    0.794\n",
      "   0|2               |    0.010|    0.438\n",
      "   1|0               |    0.046|    0.796\n",
      "   3|1               |    0.284|    0.798\n",
      "   0|2               |    0.020|    0.513\n",
      "   3|1               |    0.569|    0.801\n",
      "   0|2               |    0.039|    0.585\n",
      "   1|0               |    0.087|    0.797\n",
      "   3|1               |    1.138|    0.802\n",
      "   0|2               |    0.079|    0.620\n",
      "   1|0               |    0.142|    0.801\n",
      "   0|2               |    0.157|    0.667\n",
      "   1|0               |    0.469|    0.802\n",
      "   0|2               |    0.315|    0.667\n",
      "   3|2               |   -0.000|    0.802\n",
      "   1|0               |    0.906|    0.802\n",
      "   0|0               |   -0.000|    0.667\n",
      "   2|0               |    0.366|    0.807\n",
      "   1|1               |    0.050|    0.802\n",
      "   1|1               |   -0.166|    0.802\n",
      "   3|2               |   -0.091|    0.803\n",
      "   3|2               |   -0.363|    0.805\n",
      "   3|0               |   -0.000|    0.805\n",
      "   3|0               |   -0.000|    0.805\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.667\n",
      "   1|1               |    0.135|    0.802\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |    0.000|    0.667\n",
      "   1|1               |    0.320|    0.803\n",
      "   3|0               |   -0.000|    0.805\n",
      "   1|1               |    0.567|    0.803\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|0               |   -0.001|    0.805\n",
      "   0|0               |    0.000|    0.668\n",
      "   3|0               |   -0.003|    0.805\n",
      "   0|0               |    0.000|    0.668\n",
      "   3|0               |   -0.007|    0.806\n",
      "   1|1               |    7.967|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   0|0               |    0.000|    0.669\n",
      "   3|0               |   -0.052|    0.806\n",
      "   1|1               |   31.650|    0.803\n",
      "   1|1               |   63.227|    0.803\n",
      "   0|0               |    0.000|    0.671\n",
      "   0|0               |    0.001|    0.675\n",
      "   0|0               |    0.001|    0.682\n",
      "   0|0               |    0.002|    0.709\n",
      "   0|0               |    0.005|    0.731\n",
      "   0|0               |    0.009|    0.750\n",
      "   0|0               |    0.019|    0.774\n",
      "   0|0               |    0.038|    0.778\n",
      "   0|0               |    0.075|    0.788\n",
      "   0|0               |    0.150|    0.796\n",
      "   0|1               |    0.000|    0.796\n",
      "   4|3               |    0.050|    0.807\n",
      "   1|2               |   -0.127|    0.804\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.525|    0.805\n",
      "   1|2               |   -1.056|    0.810\n",
      "   0|1               |   -0.000|    0.796\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|1               |   -0.000|    0.797\n",
      "   3|3               |    0.000|    0.807\n",
      "   0|1               |   -0.003|    0.797\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|0               |   -0.129|    0.808\n",
      "   3|0               |   -0.188|    0.812\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.810\n",
      "   1|3               |   -0.000|    0.810\n",
      "   1|3               |   -0.002|    0.810\n",
      "   1|3               |   -0.004|    0.810\n",
      "   1|3               |   -0.165|    0.811\n",
      "   2|3               |    0.189|    0.808\n",
      "   0|1               |    0.026|    0.797\n",
      "   0|1               |    0.051|    0.797\n",
      "   0|1               |    0.102|    0.798\n",
      "   0|1               |    0.205|    0.801\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.084|    0.811\n",
      "   1|3               |    0.167|    0.811\n",
      "   1|2               |   -0.492|    0.811\n",
      "   0|0               |    0.159|    0.801\n",
      "   0|0               |    0.259|    0.802\n",
      "   0|1               |    0.198|    0.802\n",
      "   0|1               |    0.298|    0.802\n",
      "   0|1               |    1.698|    0.803\n",
      "   0|1               |    6.498|    0.803\n",
      "   0|1               |   12.898|    0.803\n",
      "   0|1               |   25.698|    0.803\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.000|    0.812\n",
      "   0|3               |   -0.021|    0.803\n",
      "   3|3               |   -0.050|    0.812\n",
      "   1|1               |    0.443|    0.811\n",
      "   0|3               |   -0.012|    0.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|3               |   -0.004|    0.803\n",
      "   0|3               |    0.096|    0.803\n",
      "   3|3               |    0.050|    0.812\n",
      "   0|3               |    0.441|    0.804\n",
      "   0|2               |    0.000|    0.804\n",
      "   0|2               |    0.003|    0.804\n",
      "   0|2               |   -0.009|    0.804\n",
      "   0|2               |   -0.047|    0.804\n",
      "   0|2               |   -0.098|    0.804\n",
      "   0|2               |   -0.199|    0.804\n",
      "   0|2               |   -0.403|    0.806\n",
      "   0|2               |   -0.810|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.007|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.007|    0.813\n",
      "   0|0               |   -0.008|    0.813\n",
      "   0|0               |   -0.010|    0.813\n",
      "   0|0               |   -0.006|    0.813\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "[+] Random restart #2/5...\n",
      "[+] Random restart #4/5...\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |    0.000|    0.798\n",
      "   1|3               |    0.000|    0.795\n",
      "   3|3               |    0.319|    0.365\n",
      "   3|3               |    0.219|    0.367\n",
      "   0|3               |   -2.972|    0.296\n",
      "   0|3               |   -6.172|    0.296\n",
      "   0|3               |  -12.572|    0.297\n",
      "   0|3               |  -25.372|    0.299\n",
      "   0|3               |  -50.972|    0.305\n",
      "   0|3               | -102.172|    0.311\n",
      "   0|3               | -204.572|    0.328\n",
      "   3|3               |  -50.781|    0.375\n",
      "   0|3               | -409.372|    0.355\n",
      "   3|3               | -101.981|    0.378\n",
      "   0|3               | -818.972|    0.368\n",
      "   3|3               | -204.381|    0.382\n",
      "   0|3               |-1638.172|    0.375\n",
      "   3|3               | -409.181|    0.383\n",
      "   0|3               |-3276.572|    0.380\n",
      "   3|3               | -818.781|    0.383\n",
      "   0|3               |-6553.372|    0.382\n",
      "   3|3               |-1637.981|    0.383\n",
      "   0|3               |-13106.972|    0.383\n",
      "   3|3               |-3276.381|    0.383\n",
      "   0|3               |-26214.172|    0.383\n",
      "   3|3               |-6553.181|    0.383\n",
      "   0|3               |-52428.572|    0.383\n",
      "   3|3               |-13106.781|    0.383\n",
      "   3|3               |-26213.981|    0.383\n",
      "   0|3               |-104857.372|    0.383\n",
      "   3|3               |-52428.381|    0.383\n",
      "   4|0               |    0.373|    0.803\n",
      "   0|3               |-209714.972|    0.383\n",
      "   3|3               |-104857.181|    0.383\n",
      "   4|0               |    0.473|    0.805\n",
      "   2|3               |    0.173|    0.802\n",
      "   0|3               |-419430.172|    0.383\n",
      "   2|3               |    0.273|    0.802\n",
      "   1|3               |    0.015|    0.795\n",
      "   0|3               |-838860.572|    0.383\n",
      "   1|3               |    0.215|    0.795\n",
      "   0|3               |-1677721.372|    0.383\n",
      "   4|1               |    0.000|    0.806\n",
      "   4|1               |   -0.224|    0.806\n",
      "   2|2               |   -0.125|    0.802\n",
      "   2|2               |   -0.312|    0.805\n",
      "   2|2               |   -0.686|    0.805\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.383\n",
      "   3|1               |    0.000|    0.384\n",
      "   3|1               |    0.000|    0.384\n",
      "   3|1               |    0.000|    0.386\n",
      "   3|1               |    0.000|    0.387\n",
      "   3|1               |    0.000|    0.388\n",
      "   3|1               |    0.000|    0.392\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.001|    0.402\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.001|    0.421\n",
      "   0|2               |    0.000|    0.383\n",
      "   3|1               |    0.002|    0.466\n",
      "   0|2               |    0.000|    0.384\n",
      "   3|1               |    0.004|    0.553\n",
      "   0|2               |    0.000|    0.384\n",
      "   3|1               |    0.009|    0.664\n",
      "   0|2               |    0.000|    0.384\n",
      "   3|1               |    0.018|    0.733\n",
      "   0|2               |    0.000|    0.386\n",
      "   3|1               |    0.036|    0.772\n",
      "   0|2               |    0.001|    0.387\n",
      "   3|1               |    0.071|    0.787\n",
      "   0|2               |    0.001|    0.389\n",
      "   3|1               |    0.142|    0.794\n",
      "   1|0               |    0.036|    0.796\n",
      "   0|2               |    0.002|    0.398\n",
      "   3|1               |    0.284|    0.798\n",
      "   0|2               |    0.005|    0.415\n",
      "   3|1               |    0.569|    0.800\n",
      "   3|1               |    1.138|    0.802\n",
      "   1|0               |    0.046|    0.796\n",
      "   0|2               |    0.010|    0.438\n",
      "   3|1               |    2.276|    0.803\n",
      "   0|2               |    0.020|    0.512\n",
      "   3|1               |    4.551|    0.803\n",
      "   0|2               |    0.039|    0.585\n",
      "   1|0               |    0.142|    0.801\n",
      "   0|2               |    0.079|    0.620\n",
      "   0|2               |    0.157|    0.666\n",
      "   1|0               |    0.469|    0.802\n",
      "   1|0               |    0.906|    0.802\n",
      "   0|2               |    0.315|    0.667\n",
      "   3|2               |   -0.000|    0.803\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |   -0.000|    0.667\n",
      "   0|0               |   -0.000|    0.667\n",
      "   0|0               |   -0.000|    0.667\n",
      "   2|0               |    0.366|    0.807\n",
      "   1|1               |    0.050|    0.802\n",
      "   3|2               |   -0.140|    0.804\n",
      "   3|2               |   -0.559|    0.806\n",
      "   1|1               |   -0.166|    0.802\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |    0.000|    0.806\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|0               |   -0.002|    0.806\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|0               |   -0.004|    0.806\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|0               |   -0.009|    0.806\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |    0.000|    0.667\n",
      "   0|0               |    0.000|    0.667\n",
      "   3|0               |   -0.070|    0.806\n",
      "   1|1               |    0.320|    0.803\n",
      "   0|0               |    0.000|    0.668\n",
      "   3|0               |   -0.141|    0.811\n",
      "   1|1               |    0.567|    0.803\n",
      "   0|0               |    0.000|    0.669\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.671\n",
      "   3|3               |    0.000|    0.813\n",
      "   0|0               |    0.001|    0.675\n",
      "   0|0               |    0.001|    0.683\n",
      "   1|1               |    7.967|    0.803\n",
      "   0|0               |    0.002|    0.711\n",
      "   0|0               |    0.005|    0.731\n",
      "   1|1               |   31.650|    0.803\n",
      "   0|0               |    0.009|    0.750\n",
      "   1|1               |   63.227|    0.803\n",
      "   0|0               |    0.019|    0.773\n",
      "   0|0               |    0.038|    0.778\n",
      "   0|0               |    0.075|    0.788\n",
      "   0|0               |    0.150|    0.797\n",
      "   0|1               |    0.000|    0.797\n",
      "   0|1               |   -0.000|    0.797\n",
      "   4|3               |    0.050|    0.807\n",
      "   1|2               |   -0.127|    0.804\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|2               |   -0.260|    0.804\n",
      "   1|2               |   -0.525|    0.805\n",
      "   1|2               |   -1.056|    0.810\n",
      "   0|1               |   -0.000|    0.797\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|2               |   -0.400|    0.815\n",
      "   1|3               |    0.001|    0.810\n",
      "   1|3               |    0.001|    0.810\n",
      "   1|3               |   -0.000|    0.810\n",
      "   1|3               |   -0.002|    0.810\n",
      "   1|3               |   -0.004|    0.810\n",
      "   2|3               |    0.189|    0.807\n",
      "   0|1               |    0.002|    0.797\n",
      "   2|3               |    0.289|    0.808\n",
      "   1|3               |   -0.165|    0.811\n",
      "   0|1               |    0.026|    0.797\n",
      "   0|1               |    0.051|    0.797\n",
      "   0|1               |    0.102|    0.799\n",
      "   0|1               |    0.205|    0.800\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.084|    0.811\n",
      "   0|0               |    0.159|    0.800\n",
      "   1|3               |    0.167|    0.811\n",
      "   0|0               |    0.259|    0.802\n",
      "   1|2               |   -0.492|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.000|    0.815\n",
      "   0|1               |    0.198|    0.802\n",
      "   0|1               |    0.298|    0.802\n",
      "   0|1               |    1.698|    0.803\n",
      "   0|1               |    6.498|    0.803\n",
      "   0|1               |   12.898|    0.803\n",
      "   0|1               |   25.698|    0.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0|3               |   -0.012|    0.803\n",
      "   0|3               |    0.096|    0.803\n",
      "   0|3               |    0.211|    0.804\n",
      "   1|0               |    0.000|    0.811\n",
      "   2|1               |   -0.082|    0.808\n",
      "   1|0               |    0.001|    0.811\n",
      "   0|2               |    0.005|    0.804\n",
      "   1|0               |   -0.002|    0.811\n",
      "   1|0               |   -0.016|    0.813\n",
      "   0|2               |   -0.116|    0.804\n",
      "   0|2               |   -0.481|    0.806\n",
      "   0|2               |   -0.966|    0.811\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.084|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |    0.000|    0.811\n",
      "   0|0               |    0.001|    0.811\n",
      "   0|0               |   -0.019|    0.813\n",
      "   0|3               |    0.093|    0.813\n",
      "   1|0               |   -0.019|    0.813\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|3               |    0.098|    0.813\n",
      "---------------------------\n",
      "Finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 8303, number of used features: 3\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@20: 0.687468\n",
      "[3]\tvalid_0's ndcg@20: 0.687804\n",
      "[4]\tvalid_0's ndcg@20: 0.699737\n",
      "[5]\tvalid_0's ndcg@20: 0.702416\n",
      "[6]\tvalid_0's ndcg@20: 0.702763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@20: 0.721738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "re = {}\n",
    "for i in range(0, 5):\n",
    "    prd = pd.read_csv('data/test_relevance_{}.csv'.format(i)).drop(columns = ['Unnamed: 0'])\n",
    "    prd['qid'] = prd['qid'].astype(str)\n",
    "    prd['docno'] = 'd'+(prd['docno'].astype(str))\n",
    "\n",
    "    sim_dict = {}\n",
    "    for index, row in prd.iterrows():\n",
    "        sim_dict[(row.qid,row.docno)] = row.sim\n",
    "\n",
    "    \n",
    "    index = pt.IndexFactory.of(index_ref)\n",
    "    bienc_ltr_feats = bm25 >> (\n",
    "        pt.transformer.IdentityTransformer()\n",
    "        ** # tf-idf\n",
    "        tf_idf\n",
    "        ** # abstract coordinate match\n",
    "        pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    "        ** # bi-encoder's relevance\n",
    "        (pt.apply.doc_score(lambda row: find_relevance(row,sim_dict)))\n",
    "    )\n",
    "\n",
    "    # rf\n",
    "    rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "    rf_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(rf)\n",
    "    rf_pipe.fit(train_topics, qrels)\n",
    "\n",
    "    # ca\n",
    "    train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "    params = train_request.params\n",
    "    params.init_random = True\n",
    "    params.normalize = True\n",
    "    params.seed = 1234567\n",
    "    ca_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "    ca_pipe.fit(train_topics, qrels)\n",
    "\n",
    "    #lmart\n",
    "    lmart_l = lgb.LGBMRanker(\n",
    "        task=\"train\",\n",
    "        silent=False,\n",
    "        min_data_in_leaf=1,\n",
    "        min_sum_hessian_in_leaf=1,\n",
    "        max_bin=255,\n",
    "        num_leaves=31,\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        ndcg_eval_at=[10],\n",
    "        ndcg_at=[10],\n",
    "        eval_at=[10],\n",
    "        learning_rate= .1,\n",
    "        importance_type=\"gain\",\n",
    "        num_iterations=100,\n",
    "        early_stopping_rounds=5\n",
    "    )\n",
    "    lmart_x_pipe.fit(train_topics, qrels, valid_topics, qrels)\n",
    "\n",
    "    temp_table = pt.Experiment(\n",
    "        [ca_pipe, rf_pipe, lmart_x_pipe,bm25], \n",
    "        test_topics,\n",
    "        qrels,\n",
    "        names=[\"fastrank\",  \"random forest\", \"LambdaMart\", \"bm25\"],\n",
    "        eval_metrics=[\"ndcg_cut_10\"]\n",
    "    )\n",
    "    temp_table = pd.DataFrame(temp_table.values.T,columns = temp_table.name,index = temp_table.columns).iloc[1:,:]\n",
    "    temp_table = pd.melt(temp_table,value_vars=['fastrank','random forest','LambdaMart'],var_name=['L2R models'])\n",
    "    temp_table['epoch'] = [i+1]*3\n",
    "    re[i] = temp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2R models</th>\n",
       "      <th>value</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.760884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.673396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.761715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.698456</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.758858</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.676477</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.762098</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.678898</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastrank</td>\n",
       "      <td>0.758858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.680951</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LambdaMart</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      L2R models     value  epoch\n",
       "0       fastrank  0.760884      1\n",
       "1  random forest  0.673396      1\n",
       "2     LambdaMart  0.614833      1\n",
       "0       fastrank  0.761715      2\n",
       "1  random forest  0.698456      2\n",
       "2     LambdaMart  0.614833      2\n",
       "0       fastrank  0.758858      3\n",
       "1  random forest  0.676477      3\n",
       "2     LambdaMart  0.614833      3\n",
       "0       fastrank  0.762098      4\n",
       "1  random forest  0.678898      4\n",
       "2     LambdaMart  0.614833      4\n",
       "0       fastrank  0.758858      5\n",
       "1  random forest  0.680951      5\n",
       "2     LambdaMart  0.614833      5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_re = pd.DataFrame()\n",
    "for i in range(0,5):\n",
    "    final_re = pd.concat([final_re,re[i]])\n",
    "final_re['epoch'] = final_re['epoch'].astype(int)\n",
    "final_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9dd48dab50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\": (10, 6)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(context='notebook', style='ticks', font_scale=1.2)\n",
    "\n",
    "ax = sns.lineplot(data = final_re[final_re[\"L2R models\"] == 'fastrank'].reset_index(), x = \"epoch\", y = \"value\", color = 'r', label = 'fastrank')\n",
    "ax = sns.lineplot(data = final_re[final_re[\"L2R models\"] == 'random forest'].reset_index(), x = \"epoch\", y = \"value\", color = 'b',label = 'random forest')\n",
    "ax = sns.lineplot(data = final_re[final_re[\"L2R models\"] == 'LambdaMart'].reset_index(), x = \"epoch\", y = \"value\", color = 'g',label = 'LambdaMart')\n",
    "\n",
    "ax.set_xlabel('number of epoches')\n",
    "ax.set_ylabel('NDCG_cut_10')\n",
    "ax.set_title(\"bi-encoder's training time influences the scores\")\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
