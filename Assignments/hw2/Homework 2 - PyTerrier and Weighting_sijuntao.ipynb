{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UxEkLc6yz6J"
   },
   "source": [
    "# SI 650 / EECS 549: Homework 2\n",
    "\n",
    "## Introduction to PyTerrier and Weighting Functions\n",
    "\n",
    "This homework is intended to expose you to other types of information retrieval and demonstrates the use of another state of the art IR library, [PyTerrier](https://github.com/terrier-org/pyterrier). \n",
    "\n",
    "The overall learning goals of the assignment across all tasks are\n",
    "  - Learn how to install (and debug) new software libraries\n",
    "  - Learn how to use PyTerrier  \n",
    "  - Understand how to use document augmentation\n",
    "  - Gain additional programming and debugging skills when working with modern IR libraries\n",
    "  - Learn how weighting functions work and are implemented\n",
    "  - Gain skills in experimentation and evaluation of IR models\n",
    "  \n",
    "Homework 2 will have you working on the following tasks to get you started:\n",
    "  - PyTerrier installation & configuration\n",
    "  - indexing a collection\n",
    "  - accessing an index\n",
    "  - using the `BatchRetrieve` transformer for searching an index\n",
    "  - conducting an `Experiment`\n",
    "  - Writing BM25 and Pivoted normalization from scratch as weighting functions\n",
    "  - Writing your own custom weighting function\n",
    "\n",
    "For all parts of the homework, you shoud run them on your local computer with enough time. We _strongly_ discourage running these on any remote system (e.g., colab) at the moment, as we have designed this homework in mind with helping you build the skills of installing and runnnig complex libraries.\n",
    "\n",
    "For each notebook, all the programming tasks that you will need to complete are marked with **Task** in a cell title comment. You will need to do a bit of analysis and writing. Writing responses should be submitted in a **separate** document than the notebook.\n",
    "\n",
    "Like many python-based IR frameworks, PyTerrier  uses a Java-based library underneith, [Terrier information retrieval toolkit](http://terrier.org), so you may need to set `JAVA_HOME` accordingly. Java is a high performance computing language and has a rich set of efficient implemenations for many indexing and retrieval operations. PyTerrier is relatively new in 2020, but Terrier has a long history dating back to 2001 and  makes it easy to perform IR experiments in Python, which could come in handy for you when doing your course project.\n",
    "\n",
    "To complete the homework, you will need to see the [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/) for many more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastrank in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (0.7.0)\n",
      "Collecting lightgbm==3.1.1\n",
      "  Using cached lightgbm-3.1.1-py2.py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: scipy in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from lightgbm==3.1.1) (1.9.3)\n",
      "Requirement already satisfied: numpy in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from lightgbm==3.1.1) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from lightgbm==3.1.1) (1.0.2)\n",
      "Requirement already satisfied: wheel in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from lightgbm==3.1.1) (0.37.1)\n",
      "Requirement already satisfied: cffi in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from fastrank) (1.15.0)\n",
      "Requirement already satisfied: attrs in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from fastrank) (21.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (2.2.0)\n",
      "Requirement already satisfied: pycparser in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from cffi->fastrank) (2.21)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting python-terrier\n",
      "  Downloading python-terrier-0.9.1.tar.gz (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.9/102.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (1.23.4)\n",
      "Requirement already satisfied: pandas in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (1.4.2)\n",
      "Requirement already satisfied: wget in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: tqdm in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (4.64.0)\n",
      "Collecting pyjnius>=1.4.2\n",
      "  Downloading pyjnius-1.4.2-cp39-cp39-macosx_10_9_x86_64.whl (276 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matchpy in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: sklearn in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.0)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: chest in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: scipy in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (1.9.3)\n",
      "Requirement already satisfied: requests in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (2.27.1)\n",
      "Requirement already satisfied: joblib in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (1.1.0)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: more_itertools in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (8.14.0)\n",
      "Requirement already satisfied: ir_datasets>=0.3.2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.5.3)\n",
      "Requirement already satisfied: jinja2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (2.11.3)\n",
      "Requirement already satisfied: statsmodels in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.13.2)\n",
      "Requirement already satisfied: ir_measures>=0.3.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.3.1)\n",
      "Requirement already satisfied: dill in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.3.5.1)\n",
      "Requirement already satisfied: pytrec_eval_terrier>=0.5.3 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from python-terrier) (0.5.4)\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (4.8.0)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (6.0)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (0.1.8)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.1)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (4.0.2)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (0.1.5)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (3.1.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_datasets>=0.3.2->python-terrier) (4.11.1)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from ir_measures>=0.3.1->python-terrier) (1.0.10)\n",
      "Requirement already satisfied: six>=1.7.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from pyjnius>=1.4.2->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from requests->python-terrier) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from requests->python-terrier) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from requests->python-terrier) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from requests->python-terrier) (3.3)\n",
      "Requirement already satisfied: heapdict in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from deprecated->python-terrier) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from jinja2->python-terrier) (2.0.1)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from pandas->python-terrier) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from pandas->python-terrier) (2021.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from sklearn->python-terrier) (1.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=21.3 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from statsmodels->python-terrier) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from statsmodels->python-terrier) (0.5.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->ir_datasets>=0.3.2->python-terrier) (2.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21.3->statsmodels->python-terrier) (3.0.4)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/junsi/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->python-terrier) (2.2.0)\n",
      "Building wheels for collected packages: python-terrier\n",
      "  Building wheel for python-terrier (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.9.1-py3-none-any.whl size=110766 sha256=2244791faf14d91c558fd97cbb46d3d720f189a5e928b4150f88838e799c37c0\n",
      "  Stored in directory: /Users/junsi/Library/Caches/pip/wheels/9e/26/80/c1a4c077dd7115b4b35c1443de7760ee1b7731d5909b110b5c\n",
      "Successfully built python-terrier\n",
      "Installing collected packages: pyjnius, deprecated, python-terrier\n",
      "  Attempting uninstall: pyjnius\n",
      "    Found existing installation: pyjnius 1.3.0\n",
      "    Uninstalling pyjnius-1.3.0:\n",
      "      Successfully uninstalled pyjnius-1.3.0\n",
      "Successfully installed deprecated-1.2.13 pyjnius-1.4.2 python-terrier-0.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fastrank lightgbm==3.1.1\n",
    "!pip install python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Helpful for showing indexing information\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "import pyterrier as pt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH0Ds2370V0G"
   },
   "source": [
    "### Starting PyTerrier\n",
    "\n",
    "The first step is to initialise PyTerrier using PyTerrier's `init()` method. The `init()` method will download Terrier's jar file (if it's not already) and then start the Java Virtual Machine. To avoid downstream complications, we check `started()` prior to calling `init()` to prevent multiple Terrier instances from running concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17656,
     "status": "ok",
     "timestamp": 1615971633689,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "Z4qALBa90-7g",
    "outputId": "378c8773-686c-4abc-d1b5-af80d18cfed0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qqjVSu-5_FX"
   },
   "source": [
    "### Documents, Indexing and Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3soS1IIy5B83"
   },
   "source": [
    "PyTerrier typically works with Pandas dataframes for inputs. Let's create a toy set of documents in a dataframe to test. Note that the column name of `docno` is a special PyTerrier name that is the unique identifier for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 14933,
     "status": "ok",
     "timestamp": 1615971633692,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "gSEiEuTE5uyL",
    "outputId": "8ef282f5-94df-403f-c501-6147f62d2de8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>this is the first document of many documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>this is another document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>the topic of this document is unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                          text\n",
       "0    d1  this is the first document of many documents\n",
       "1    d2                      this is another document\n",
       "2    d3         the topic of this document is unknown"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df = pd.DataFrame([\n",
    "        [\"d1\", \"this is the first document of many documents\"],\n",
    "        [\"d2\", \"this is another document\"],\n",
    "        [\"d3\", \"the topic of this document is unknown\"]\n",
    "    ], columns=[\"docno\", \"text\"])\n",
    "\n",
    "docs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RCtCCTU6GAj"
   },
   "source": [
    "Before any search engine can estimate which documents are most likely to be relevant for a given query, it must index the documents. \n",
    "\n",
    "In the following cell, we index the dataframe's documents. The index, with all its data structures, is written into a directory called `toydocs_index`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 2312,
     "status": "ok",
     "timestamp": 1615971681350,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "1YvLhEOS6V8w",
    "outputId": "ebe4070d-7160-42ba-bbfe-e5ccc2f3165b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./toydocs_index/data.properties'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dir = './toydocs_index'\n",
    "indexer = pt.DFIndexer(index_dir, overwrite=True)\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index_ref.toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUm6r6_625gW"
   },
   "source": [
    "PyTerrier will generate a index in the `toydocs_index` directory and and we can list the files to see what kind of internal structure and files it made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1615971697027,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "TF45pl5O8p7R",
    "outputId": "c039d811-aebe-4e4d-f1d4-18b2b989d4c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.inverted.bf',\n",
       " 'data.direct.bf',\n",
       " 'data.lexicon.fsomaphash',\n",
       " 'data.lexicon.fsomapfile',\n",
       " 'data.properties',\n",
       " 'data.document.fsarrayfile',\n",
       " 'data.meta-0.fsomapfile',\n",
       " 'data.meta.zdata',\n",
       " 'data.meta.idx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(index_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not necessary, we encourage you to take a look at some of these files. What's in them? Do they make any sense? For fun, it can be useful to go find the python (or Java) code that reads these files and try to understand what makes up the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2b8isFP3Kv6"
   },
   "source": [
    "Once we've generated the files associated with `index_ref`, we can load the information into an actual PyTerrier index using the method `pt.IndexFactory.of()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1615971763026,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "TTM17szD6pNy",
    "outputId": "0d00514e-b30f-4b0c-a991-d618d24bb756"
   },
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZe3HD5i7G3v"
   },
   "source": [
    "See Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) object for documentation, which is written in Java's Javadoc format. We can call these methods on our index object as well. Important methods to note are:\n",
    " - `getCollectionStatistics()`\n",
    " - `getInvertedIndex()`\n",
    " - `getLexicon()`\n",
    "\n",
    "Let's see what is returned by the `CollectionStatistics()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1615972787602,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "6-gXEDSX65bx",
    "outputId": "5491223b-5b50-48c2-8232-d75970e2c2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n",
      "Number of terms: 4\n",
      "Number of postings: 6\n",
      "Number of fields: 0\n",
      "Number of tokens: 7\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6HrR4lc7i10"
   },
   "source": [
    "Let's unpack the statistics a bit more. We have 3 documents but why do we have only 4 unique terms? We can look at which terms we have by getting the [`Lexicon`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html) object, which contains our vocabulary. We can iterate over the `Lexicon` from Python like a dictionary to see which terms are present and whaht information there is about each term after indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1615971875714,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "us2mAzTW7Bny",
    "outputId": "e10d37e2-84a4-448d-9ed9-3d72a5ad5ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document (<class 'str'>) -> term0 Nt=3 TF=4 maxTF=2 @{0 0 0} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n",
      "first (<class 'str'>) -> term1 Nt=1 TF=1 maxTF=1 @{0 0 7} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n",
      "topic (<class 'str'>) -> term2 Nt=1 TF=1 maxTF=1 @{0 1 1} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n",
      "unknown (<class 'str'>) -> term3 Nt=1 TF=1 maxTF=1 @{0 1 5} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n"
     ]
    }
   ],
   "source": [
    "for kv in index.getLexicon():\n",
    "    # Let's all print the type information of each to get a sense of what we're working with\n",
    "    print(\"%s (%s) -> %s (%s)\" % (kv.getKey(), type(kv.getKey()), kv.getValue().toString(), type(kv.getValue()) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwbp94gh86pw"
   },
   "source": [
    "Iterating over the `Lexicon` shows that we're mapping a `String ` term to a [`LexiconEntry`](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object, which itself is an [`EntryStatistics`](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html). The `LexiconEntry` contains information including the statistics of that term.\n",
    "\n",
    "Looking at what we indexed reveals that PyTerrier is removing stopwords for us, much like Pyserini did. PyTerrier is also doing some token normalization as well so that we only have \"document\" in our index, even though document `d1` has the token \"documents\"! By default Terrier removes standard stopwords and applies Porter's stemmer (which we talked about in class), though these behaviors can be configured.\n",
    "\n",
    "The `EntryStatistics` also provides a few other fields that offer insights:\n",
    " - `Nt` is the number of unique documents that each term occurs in – this is useful for calculating IDF.\n",
    " - `TF` is the total number of occurrences – some weighting models use this instead of Nt.\n",
    " - The numbers in the `@{}` are a pointer – they tell Terrier where the postings are for that term in the inverted index data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTerrier also supports directly looking up a word using the `[]` operator, much like we would if we were looking up a key's value in a dictionary. Let's look up the value for the word \"document\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1615972070133,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "SZmi9498-Ijw",
    "outputId": "1dccc860-2f99-4e62-b1cc-da4918003b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term0 Nt=3 TF=4 maxTF=2 @{0 0 0}\n"
     ]
    }
   ],
   "source": [
    "print(index.getLexicon()[\"document\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaKaU59l-kzg"
   },
   "source": [
    "We can use the information in the `Lexicon` to also look up documents as well. Remember from class that an inverted index is a mapping from a term to which *documents* each term occurs in. The `LexiconEntry` for a word contains the pointer to where to find the documents for that word in the inverted index. \n",
    "\n",
    "The object retrieved from using the `[]` operator with a `Lexicon` is a pointer that we can use with the inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1615972108524,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "XQki_Pds8ut2",
    "outputId": "f7824c65-33d9-499f-f9dc-97d8d7e652c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID(0) TF(2) doclen=3\n",
      "ID(1) TF(1) doclen=1\n",
      "ID(2) TF(1) doclen=3\n"
     ]
    }
   ],
   "source": [
    "pointer = index.getLexicon()[\"document\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(str(posting) + \" doclen=%d\" % posting.getDocumentLength())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EaoIIO_DPx"
   },
   "source": [
    "From this output, we can see that the term \"document\" occurs in all three documents, as well as how long those documents are. Note that PyTerrier starts counting indexed documents with `int` values starting from 0 (called *docids*). These *docids* are then mapped back to *docnos*, which are the unique string identifiers for a document, e.g., the \"`d1`\", \"`d2`\" we used. This mapping is stored in a separate data structure called the *metaindex*, though you likely won't need to use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOSdVAr-CGRf"
   },
   "source": [
    "## Searching an Index\n",
    "\n",
    "Our way into search in PyTerrier is called `BatchRetrieve`. BatchRetrieve is configured by specifying an index and a weighting model. Here', we'll use the `Tf` weighting, which is just term frequency; there are multiple possible weighting schemes, as we'll see later. Using a `BatchRetrieve` object, we will search for a single-word query, `\"document\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1615972796605,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "XtK93nwXCF5C",
    "outputId": "f10dccb8-7d91-44ba-8afa-b21b32022999"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid docno  rank  score     query\n",
       "0   1      0    d1     0    2.0  document\n",
       "1   1      1    d2     1    1.0  document\n",
       "2   1      2    d3     2    1.0  document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "br.search(\"document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHqSfTCtDM2T"
   },
   "source": [
    "The `search()` method returns a Pandas dataframe with columns:\n",
    " - `qid`: this is the query id, which is by default \"1\", since we issued only one query\n",
    " - `docid`: Terrier' internal integer for each document\n",
    " - `docno`: the external (string) unique identifier for each document\n",
    " - `score`: since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n",
    " - `rank`: A handy attribute showing the descending order by score\n",
    " - `query`: the input query\n",
    "\n",
    "As expected, the `Tf` weighting model used here only counts the frequencies of the query terms in each document, i.e.:\n",
    "$$\n",
    "score(d,q) = \\sum_{t \\in q} tf_{t,d}\n",
    "$$\n",
    "This is the \"Raw TF\" model we discussed in class! \n",
    "\n",
    "Hence, it's clear that document `d1` should be the highest scored document with two occurrences (c.f. `'document'` and `'documents'`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJBXquPOD6q7"
   },
   "source": [
    "### Searching with multiple queries\n",
    "\n",
    "We can search for more than one query at a time using the  `transform()` method rather than the `search()` method. PyTerrier uses the notion of transformers, which we'll describe much more in Part 2, but for now, you can think of this function as transforming some input to some output. In our case, we'll create a Pandas DataFrame with our queries, which we'll provide as input to the `BatchRetrieve` object, to \"tranform\" into results.\n",
    "\n",
    "Note that we not only need to provide queries, but also query identifiers in the `qid` column. These `qid` values will let us distinguish which results go to which query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q2</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid           query\n",
       "0  q1        document\n",
       "1  q2  first document"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.DataFrame([[\"q1\", \"document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this queries data frame into `transform()` to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1615972799893,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "TPBmPOETBKWk",
    "outputId": "69bf68d3-5e95-403d-f5f8-76bbd7cdaba9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q1</td>\n",
       "      <td>1</td>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q1</td>\n",
       "      <td>2</td>\n",
       "      <td>d3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q2</td>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q2</td>\n",
       "      <td>1</td>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q2</td>\n",
       "      <td>2</td>\n",
       "      <td>d3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid docno  rank  score           query\n",
       "0  q1      0    d1     0    2.0        document\n",
       "1  q1      1    d2     1    1.0        document\n",
       "2  q1      2    d3     2    1.0        document\n",
       "3  q2      0    d1     0    3.0  first document\n",
       "4  q2      1    d2     1    1.0  first document\n",
       "5  q2      2    d3     2    1.0  first document"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcgDzFLBEWAI"
   },
   "source": [
    "Most common operations in PyTerrier have be overloaded so that you can call them using python syntax (called _operator overloading_). We'll discuss this more in Part 2, but for now, know that you can call `br.transform(queries)` using just `br(queries)`. Here. the `()` operator has been overloaded so that it calls `transform()` for us! You will see this usage very frequently in examples and documentation so it's worth noting and remembering the two are equivalent. As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1615972806683,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "YCwxb3HhEOp_",
    "outputId": "b0cfe94b-c1d7-4ac8-811d-befc9771ce32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q1</td>\n",
       "      <td>1</td>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q1</td>\n",
       "      <td>2</td>\n",
       "      <td>d3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q2</td>\n",
       "      <td>0</td>\n",
       "      <td>d1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q2</td>\n",
       "      <td>1</td>\n",
       "      <td>d2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q2</td>\n",
       "      <td>2</td>\n",
       "      <td>d3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid docno  rank  score           query\n",
       "0  q1      0    d1     0    2.0        document\n",
       "1  q1      1    d2     1    1.0        document\n",
       "2  q1      2    d3     2    1.0        document\n",
       "3  q2      0    d1     0    3.0  first document\n",
       "4  q2      1    d2     1    1.0  first document\n",
       "5  q2      2    d3     2    1.0  first document"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the exact same results as our earlier call to `br.transform(queries)`, just like we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldY8VV8wQ60Z"
   },
   "source": [
    "## Working with real data\n",
    "\n",
    "Let's move on to our full dataset, the NF Corpus (Nutrition Facts), which is easily accessible online. We'll use PyTerrier's `get_dataset()` function to download this corpus automatically and then to index it. This dataset is designed to test IR in a full-text English retrieval setting for Medical Information Retrieval. We'll use this for the initial two groups of tasks and then switch datasets later.\n",
    " \n",
    "### Task 1.1 (5 points):\n",
    "\n",
    "You first task will be to write three lines of code that create the index using an indexer or, if the index was already created, loads the created index from file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120273,
     "status": "ok",
     "timestamp": 1615972928650,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "L2lJsK-vEcQx",
    "outputId": "bcdfe9c5-7950-4974-a97d-ab3764995115"
   },
   "outputs": [],
   "source": [
    "nf_dataset = pt.datasets.get_dataset('irds:nfcorpus/dev') \n",
    "pt_index_path = './nfcorpus_dev'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    # TODO\n",
    "    iter_indexer = pt.IterDictIndexer(pt_index_path)\n",
    "\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record   \n",
    "    # TODO\n",
    "    index_ref = iter_indexer.index(nf_dataset.get_corpus_iter(), fields = ('abstract', ), meta=('docno', ))\n",
    "\n",
    "else:\n",
    "    # if you already have the index, create an IndexRef from the data in pt_index_path\n",
    "    # that we can use to load using the IndexFactory\n",
    "    # TODO\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "    \n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7GK9uANRt8w"
   },
   "source": [
    "### Task 1.2 (0 points but useful still)\n",
    "- Print out the statistics of the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bNAVqf9uRr2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 5371\n",
      "Number of terms: 18315\n",
      "Number of postings: 499136\n",
      "Number of fields: 1\n",
      "Number of tokens: 801411\n",
      "Field names: [abstract]\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQD9Q8CqSirN"
   },
   "source": [
    "As a curated collection for evaluation, NFCorpus has a corresponding set of queries, referred to as _topics_, and the relevance assessments for each query (i.e., topic), referred to as _qrels_. We use these to evaluation as a *test collection*. PyTerrier allows us to easily access the topics (queries) and qrels from the dataset. Like much of the inputs and outputs, these are expressed as dataframes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1615972942774,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "8n7oY-YYS_-A",
    "outputId": "6ff6f437-725f-4b92-bfab-787e18386941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>ddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>how to treat multiple sclerosis with diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>detoxification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>dietary guidelines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid                                      query\n",
       "0     PLAIN-1      why deep fried foods may cause cancer\n",
       "1  PLAIN-1007                                        ddt\n",
       "2   PLAIN-101  how to treat multiple sclerosis with diet\n",
       "3  PLAIN-1017                             detoxification\n",
       "4  PLAIN-1027                         dietary guidelines"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_dataset.get_topics(variant='title').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 1704,
     "status": "ok",
     "timestamp": 1615972945620,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "-rYxqvhJTGNX",
    "outputId": "e4db9772-f10f-4133-bc25-aee1a6f5a0ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>MED-2421</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>MED-2422</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>MED-2416</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>MED-2423</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>MED-2417</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid     docno  label iteration\n",
       "0  PLAIN-1  MED-2421      3         0\n",
       "1  PLAIN-1  MED-2422      3         0\n",
       "2  PLAIN-1  MED-2416      3         0\n",
       "3  PLAIN-1  MED-2423      3         0\n",
       "4  PLAIN-1  MED-2417      3         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_dataset.get_qrels().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Build indices for the same documents with different preprocessing steps (5 points)\n",
    "\n",
    "In homework 1, you tried out different approaches to filtering and tokenizing. What effect might these have in practice on a real index&mdash;and critically, on retrieval performance? PyTerrier supports modifying how an index is preprocessed via its [Indexing Configuration](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html#indexing-configuration) options. \n",
    "\n",
    "Your task is to build *at least two* different versions of the NFCorpus index using different preprocessing steps. You are free to chose different configurations that might interest you. Once you have finished, print out the statistics below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 5371\n",
      "Number of terms: 18678\n",
      "Number of postings: 671117\n",
      "Number of fields: 1\n",
      "Number of tokens: 1262132\n",
      "Field names: [abstract]\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# configuration 1: \n",
    "# stemming configuation or stopwords: termpipelines - PorterStemmer\n",
    "# languages and tokenisation: tokeniser - UTFTokeniser\n",
    "\n",
    "pt_index_path1 = './nfcorpus1_dev'\n",
    "if not os.path.exists(pt_index_path1 + \"/data.properties\"):\n",
    "    iter_indexer1 = pt.IterDictIndexer(pt_index_path1)\n",
    "    iter_indexer1.setProperty(\"termpipelines\",\"PorterStemmer\")\n",
    "    iter_indexer1.setProperty(\"tokeniser\", \"UTFTokeniser\")\n",
    "    index_ref1 = iter_indexer1.index(nf_dataset.get_corpus_iter(), fields = ('abstract', ), meta=('docno', ))\n",
    "else:\n",
    "    index_ref1 = pt.IndexRef.of(pt_index_path1 + \"/data.properties\")\n",
    "    \n",
    "index1 = pt.IndexFactory.of(index_ref1)\n",
    "\n",
    "print(index1.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 5371\n",
      "Number of terms: 25522\n",
      "Number of postings: 530609\n",
      "Number of fields: 1\n",
      "Number of tokens: 802157\n",
      "Field names: [abstract]\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# configuration 2: \n",
    "# stemming configuation or stopwords: termpipelines - Stopwords\n",
    "# languages and tokenisation: tokeniser - UTFTokeniser\n",
    "\n",
    "pt_index_path2 = './nfcorpus2_dev'\n",
    "if not os.path.exists(pt_index_path2 + \"/data.properties\"):\n",
    "    iter_indexer2 = pt.IterDictIndexer(pt_index_path2)\n",
    "    iter_indexer2.setProperty(\"termpipelines\", \"Stopwords\")\n",
    "    iter_indexer2.setProperty(\"tokeniser\", \"UTFTokeniser\")\n",
    "    index_ref2 = iter_indexer2.index(nf_dataset.get_corpus_iter(), fields = ('abstract', ), meta=('docno', ))\n",
    "else:\n",
    "    index_ref2 = pt.IndexRef.of(pt_index_path2 + \"/data.properties\")\n",
    "    \n",
    "index2 = pt.IndexFactory.of(index_ref2)\n",
    "\n",
    "print(index2.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 5371\n",
      "Number of terms: 26492\n",
      "Number of postings: 530372\n",
      "Number of fields: 1\n",
      "Number of tokens: 800475\n",
      "Field names: [abstract]\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# configuration 3: \n",
    "# stemming configuation or stopwords: termpipelines - PorterStemmer\n",
    "# languages and tokenisation: tokeniser - UTFTwitterTokeniser\n",
    "\n",
    "pt_index_path3 = './nfcorpus3_dev'\n",
    "if not os.path.exists(pt_index_path3 + \"/data.properties\"):\n",
    "    iter_indexer3 = pt.IterDictIndexer(pt_index_path3)\n",
    "    iter_indexer3.setProperty(\"termpipelines\",\"Stopwords\")\n",
    "    iter_indexer3.setProperty(\"tokeniser\", \"UTFTwitterTokeniser\")\n",
    "    index_ref3 = iter_indexer3.index(nf_dataset.get_corpus_iter(), fields = ('abstract', ), meta=('docno', ))\n",
    "else:\n",
    "    index_ref3 = pt.IndexRef.of(pt_index_path3 + \"/data.properties\")\n",
    "    \n",
    "index3 = pt.IndexFactory.of(index_ref3)\n",
    "\n",
    "print(index3.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4 Write-up your observations on what differs between them (5 points)\n",
    "\n",
    "What effect did the preprocessing have on the index? You should look at the statistics but you can also comment on performance things like file sizes and indexing time. In *at least 4 sentences* describe what differences you see and whether you were surprised by any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in your write-up\n",
    "\n",
    "# see si650_hw2_sijuntao.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Gop4-jVbIIu"
   },
   "source": [
    "### Weighting Models\n",
    "\n",
    "In the earlier example, we used the simple \"`Tf`\" as our ranking function for document retrieval in BatchRetrieve. However, we can use other models such as `\"TF_IDF\"` by simply changing the `wmodel=\"Tf\"` keyword argument in the constructor of `BatchRetrieve`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1615973062514,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "Cg8AGzCibdPG",
    "outputId": "bc353f41-1c33-468c-a834-37a93f1d0ced"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4523</td>\n",
       "      <td>MED-4524</td>\n",
       "      <td>0</td>\n",
       "      <td>6.382897</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>MED-441</td>\n",
       "      <td>1</td>\n",
       "      <td>6.203472</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3267</td>\n",
       "      <td>MED-3268</td>\n",
       "      <td>2</td>\n",
       "      <td>6.203472</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3281</td>\n",
       "      <td>MED-3282</td>\n",
       "      <td>3</td>\n",
       "      <td>6.203472</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4903</td>\n",
       "      <td>MED-4904</td>\n",
       "      <td>4</td>\n",
       "      <td>6.171522</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1</td>\n",
       "      <td>3944</td>\n",
       "      <td>MED-3945</td>\n",
       "      <td>420</td>\n",
       "      <td>1.909530</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>1</td>\n",
       "      <td>1347</td>\n",
       "      <td>MED-1348</td>\n",
       "      <td>421</td>\n",
       "      <td>1.860415</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>1</td>\n",
       "      <td>3718</td>\n",
       "      <td>MED-3719</td>\n",
       "      <td>422</td>\n",
       "      <td>1.849169</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>MED-870</td>\n",
       "      <td>423</td>\n",
       "      <td>1.822288</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>MED-1846</td>\n",
       "      <td>424</td>\n",
       "      <td>1.811005</td>\n",
       "      <td>chemical reactions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid  docid     docno  rank     score               query\n",
       "0     1   4523  MED-4524     0  6.382897  chemical reactions\n",
       "1     1    440   MED-441     1  6.203472  chemical reactions\n",
       "2     1   3267  MED-3268     2  6.203472  chemical reactions\n",
       "3     1   3281  MED-3282     3  6.203472  chemical reactions\n",
       "4     1   4903  MED-4904     4  6.171522  chemical reactions\n",
       "..   ..    ...       ...   ...       ...                 ...\n",
       "420   1   3944  MED-3945   420  1.909530  chemical reactions\n",
       "421   1   1347  MED-1348   421  1.860415  chemical reactions\n",
       "422   1   3718  MED-3719   422  1.849169  chemical reactions\n",
       "423   1    869   MED-870   423  1.822288  chemical reactions\n",
       "424   1   1845  MED-1846   424  1.811005  chemical reactions\n",
       "\n",
       "[425 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "tfidf.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6aZGX9sbdmc"
   },
   "source": [
    "Note that, as expected, because we switched the ranking, the scores of documents ranked by `TF_IDF` are no longer integers. You can see the exact TF-IDF formula used by Terrier from [the Github repo](https://github.com/terrier-org/terrier-core/blob/5.x/modules/core/src/main/java/org/terrier/matching/models/TF_IDF.java#L79)--sometimes helpful to know since there are multiple ways of defining TF-IDF! Terrier supports many weighting models and the documentation contains [a list of supported models](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ0j9lFfx-gO"
   },
   "source": [
    "## Evaluating and Comparing IR Models\n",
    "\n",
    "How do we know which of the models we've made so far are good IR models? PyTerrier provides a robust and extensive framework to help us automate the evaluation of IR models once wee've defined them.\n",
    "\n",
    "As a first pass, let's take a look at the relevance scores in the dataset. To do this, we'll merge (`join`) the `qrels` with the results of our ranker to produce a dataframe that has both the ranking model's predictions (`\"score\"`) and the actual relevance score (`\"label\"`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1615973109097,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "iyShZYpwwNSx",
    "outputId": "91f1ae8b-8f3a-4547-ae37-d9d808c970ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>5</td>\n",
       "      <td>MED-6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.407378</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>2417</td>\n",
       "      <td>MED-2418</td>\n",
       "      <td>1</td>\n",
       "      <td>18.407378</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>5268</td>\n",
       "      <td>MED-5269</td>\n",
       "      <td>2</td>\n",
       "      <td>13.991407</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>2414</td>\n",
       "      <td>MED-2415</td>\n",
       "      <td>3</td>\n",
       "      <td>12.303626</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>4063</td>\n",
       "      <td>MED-4064</td>\n",
       "      <td>4</td>\n",
       "      <td>12.303626</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>830</td>\n",
       "      <td>MED-831</td>\n",
       "      <td>995</td>\n",
       "      <td>3.092051</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>984</td>\n",
       "      <td>MED-985</td>\n",
       "      <td>996</td>\n",
       "      <td>3.088660</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>4510</td>\n",
       "      <td>MED-4511</td>\n",
       "      <td>997</td>\n",
       "      <td>3.084229</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>3872</td>\n",
       "      <td>MED-3873</td>\n",
       "      <td>998</td>\n",
       "      <td>3.081767</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>3877</td>\n",
       "      <td>MED-3878</td>\n",
       "      <td>999</td>\n",
       "      <td>3.081767</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid  docid     docno  rank      score  \\\n",
       "0    PLAIN-1      5     MED-6     0  18.407378   \n",
       "1    PLAIN-1   2417  MED-2418     1  18.407378   \n",
       "2    PLAIN-1   5268  MED-5269     2  13.991407   \n",
       "3    PLAIN-1   2414  MED-2415     3  12.303626   \n",
       "4    PLAIN-1   4063  MED-4064     4  12.303626   \n",
       "..       ...    ...       ...   ...        ...   \n",
       "995  PLAIN-1    830   MED-831   995   3.092051   \n",
       "996  PLAIN-1    984   MED-985   996   3.088660   \n",
       "997  PLAIN-1   4510  MED-4511   997   3.084229   \n",
       "998  PLAIN-1   3872  MED-3873   998   3.081767   \n",
       "999  PLAIN-1   3877  MED-3878   999   3.081767   \n",
       "\n",
       "                                     query  label iteration  \n",
       "0    why deep fried foods may cause cancer    0.0         0  \n",
       "1    why deep fried foods may cause cancer    3.0         0  \n",
       "2    why deep fried foods may cause cancer    0.0         0  \n",
       "3    why deep fried foods may cause cancer    0.0         0  \n",
       "4    why deep fried foods may cause cancer    0.0         0  \n",
       "..                                     ...    ...       ...  \n",
       "995  why deep fried foods may cause cancer    0.0         0  \n",
       "996  why deep fried foods may cause cancer    0.0         0  \n",
       "997  why deep fried foods may cause cancer    0.0         0  \n",
       "998  why deep fried foods may cause cancer    0.0         0  \n",
       "999  why deep fried foods may cause cancer    0.0         0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = nf_dataset.get_qrels()\n",
    "\n",
    "def get_res_with_labels(ranker, df):\n",
    "    # get the results for the query or queries\n",
    "    results = ranker( df )\n",
    "    # left outer join with the qrels\n",
    "    with_labels = results.merge(qrels, on=[\"qid\", \"docno\"], how=\"left\").fillna(0)\n",
    "    return with_labels\n",
    "\n",
    "# lets get the Tf results for the first query\n",
    "get_res_with_labels(tfidf, nf_dataset.get_topics(variant='title').head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an Experiment\n",
    "\n",
    "We don't actually need to produce that dataframe to do our evaluation though! PyTerrier lets us run different results with an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) object, which will compare models according to the evaluation metrics we specify. Here, let's run an experiment to evaluate our `tfidf` model that we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 3826,
     "status": "ok",
     "timestamp": 1615973119937,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "OFUmiFSobUDg",
    "outputId": "db01e114-e6e7-4ff4-9447-ecf5e3d8ea54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(TF_IDF)</td>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.227368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       map      ndcg\n",
       "0  BR(TF_IDF)  0.087904  0.227368"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [tfidf],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt0iPhRw2J-S"
   },
   "source": [
    "## Task 2.1: Define new models and evaluate them in an Experiment (5 points)\n",
    "\n",
    "Now comes the fun part! Your task is to define **three** new [`BatchRetrieve`](https://pyterrier.readthedocs.io/en/latest/terrier-retrieval.html#batchretrieve) objects with different word ranking methods. You are welcome to set the hyperparameters but all models should be sufficiently different. You are definitely welcome (encouraged, even!) to compare _more_ than three models too.\n",
    "\n",
    "Once you have defined your three `BatchRetrieve` objects, conduct an `Experiment` using all of them _at once_ (not three separate `Experiment` runs!) to evlauate the results.  Your experiment should include the two metrics used above, as well as NDCG for the top-5 and top-10 results. You are welcome to include other metrics as well\n",
    "\n",
    "Print the results of each Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "      <td>0.224962</td>\n",
       "      <td>0.443892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR(DPH)</td>\n",
       "      <td>0.085551</td>\n",
       "      <td>0.224241</td>\n",
       "      <td>0.247755</td>\n",
       "      <td>0.223596</td>\n",
       "      <td>0.434890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR(Hiemstra_LM)</td>\n",
       "      <td>0.084659</td>\n",
       "      <td>0.222819</td>\n",
       "      <td>0.248285</td>\n",
       "      <td>0.218576</td>\n",
       "      <td>0.432179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR(DFIC)</td>\n",
       "      <td>0.084248</td>\n",
       "      <td>0.222493</td>\n",
       "      <td>0.242503</td>\n",
       "      <td>0.219932</td>\n",
       "      <td>0.432823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR(PL2)</td>\n",
       "      <td>0.086552</td>\n",
       "      <td>0.225036</td>\n",
       "      <td>0.251854</td>\n",
       "      <td>0.222980</td>\n",
       "      <td>0.437066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name       map      ndcg    nDCG@5   nDCG@10  recip_rank\n",
       "0         BR(BM25)  0.087705  0.226371  0.253002  0.224962    0.443892\n",
       "1          BR(DPH)  0.085551  0.224241  0.247755  0.223596    0.434890\n",
       "2  BR(Hiemstra_LM)  0.084659  0.222819  0.248285  0.218576    0.432179\n",
       "3         BR(DFIC)  0.084248  0.222493  0.242503  0.219932    0.432823\n",
       "4          BR(PL2)  0.086552  0.225036  0.251854  0.222980    0.437066"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compare existing models\n",
    "from pyterrier.measures import *\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "dph = pt.BatchRetrieve(index, wmodel=\"DPH\")\n",
    "hiemstra_lm = pt.BatchRetrieve(index, wmodel=\"Hiemstra_LM\")\n",
    "dfic = pt.BatchRetrieve(index, wmodel=\"DFIC\")\n",
    "pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25, dph, hiemstra_lm, dfic, pl2],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"ndcg\", nDCG@5, nDCG@10, \"recip_rank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 Describe the results of your experiments (5 points)\n",
    "\n",
    "Write 2-3 sentences (or more) about what you see in the performance. Is there a clear better model? Would you expect better performance with some hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in separate document\n",
    "\n",
    "# see si650_hw2_sijuntao.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Custom weighting\n",
    "\n",
    "PyTerrier allows you to [write your own weighting functions](\n",
    "https://pyterrier.readthedocs.io/en/latest/terrier-retrieval.html#custom-weighting-models). In this part of the assignment, we'll use this functionality to re-implement two standard weighting functions: BM25 and Pivoted Normalization. You likely will have used the built in versions of at least one of these above! The goals of having you re-implement these functions are (1) to understand how the index's data structures can be used to score document relevance efficiently and (2) to get you a better sense of how the equations we discussed in class map on to code. \n",
    "\n",
    "You are welcome to check whether your code is correct by comparing your results/weighting with PyTerrier's implementation's outputs. However, note that they may be using different hyperparameters, which could give slightly different results. This doesn't mean your code is incorrect though!\n",
    "\n",
    "### Task 3.1 Implement BM25 (10 points)\n",
    "\n",
    "Re-implement BM25 using the parameters $k_1$ = 1.2, $b$=0.75, $k_3$=8 (this is what PyTerrier also uses). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mRjyEZ5_aTvM"
   },
   "outputs": [],
   "source": [
    "def bm25_weighting(keyFreq, posting, entryStats, collStats):\n",
    "    '''\n",
    "    Computes the Okapi BM25 score of this document for a given query\n",
    "    \n",
    "    :param keyFrequency(float): the weight of the term in the query, usually 1 except during PRF.\n",
    "    :param posting(Posting): access to the information about the occurrence of the term in the current document (frequency, document length etc).\n",
    "    :param entryStats(EntryStatistics): access to the information about the occurrence of the term in the whole index (document frequency, etc.).\n",
    "    :param collStats(CollectionStatistics): access to the information about the index as a whole (number of documents, etc).\n",
    "    :return: the Okapi BM25 score of this document for the given query\n",
    "    '''\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 Implement Pivoted Normalization (10 points)\n",
    "\n",
    "Re-implement Pivoted Normalization using the parameters $b$ = 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivoted_normalization_weighting(keyFreq, posting, entryStats, collStats):\n",
    "    '''\n",
    "    Computes the Pivoted Normalization score of this document for a given query\n",
    "    \n",
    "    :param keyFrequency(float): the weight of the term in the query, usually 1 except during PRF.\n",
    "    :param posting(Posting): access to the information about the occurrence of the term in the current document (frequency, document length etc).\n",
    "    :param entryStats(EntryStatistics): access to the information about the occurrence of the term in the whole index (document frequency, etc.).\n",
    "    :param collStats(CollectionStatistics): access to the information about the index as a whole (number of documents, etc).\n",
    "    :return: the Pivoted Normalization score of this document for the given query\n",
    "    '''\n",
    "    c_w_Q = keyFreq                              # the frequency of the word in the query\n",
    "    c_w_D = posting.getFrequency()               # the frequency of the word in the current document, in tokens\n",
    "    b = 0.75\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the word occurs in\n",
    "    \n",
    "    TF = c_w_Q\n",
    "    normalized_TF = (1+math.log(1+math.log(c_w_D))) / (1-b+b*Ld/Lavg)\n",
    "    ln_IDF = math.log((N+1)/df)\n",
    "    \n",
    "    sim_term = TF * normalized_TF * ln_IDF\n",
    "    return sim_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3 Score your implementations in an Experiment on the evaluation data of each index for all datasets (5 points)\n",
    "\n",
    "Now the time has come to see how well the implementations work! Create a new series of experiments to test how well these functions work on _each_ index you created above. Each index will (likely) have a different set of terms and frequencies, some of which might be better for helping find the most relevant document.\n",
    "\n",
    "Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pivoted_normalization</td>\n",
       "      <td>0.078407</td>\n",
       "      <td>0.218938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map      ndcg\n",
       "0                   BM25  0.087705  0.226371\n",
       "1  pivoted_normalization  0.078407  0.218938"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# default index\n",
    "\n",
    "bm25_wt = pt.BatchRetrieve(index, wmodel=bm25_weighting)\n",
    "p_n_wt = pt.BatchRetrieve(index, wmodel=pivoted_normalization_weighting)\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25_wt, p_n_wt],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25\",  \"pivoted_normalization\"], \n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.081279</td>\n",
       "      <td>0.221484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pivoted_normalization</td>\n",
       "      <td>0.075295</td>\n",
       "      <td>0.219736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map      ndcg\n",
       "0                   BM25  0.081279  0.221484\n",
       "1  pivoted_normalization  0.075295  0.219736"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 1 \n",
    "# stemming configuation or stopwords: termpipelines - PorterStemmer\n",
    "# languages and tokenisation: tokeniser - UTFTokeniser\n",
    "\n",
    "bm25_wt = pt.BatchRetrieve(index1, wmodel=bm25_weighting)\n",
    "p_n_wt = pt.BatchRetrieve(index1, wmodel=pivoted_normalization_weighting)\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25_wt, p_n_wt],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25\",  \"pivoted_normalization\"], \n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.074841</td>\n",
       "      <td>0.200378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pivoted_normalization</td>\n",
       "      <td>0.069566</td>\n",
       "      <td>0.195017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map      ndcg\n",
       "0                   BM25  0.074841  0.200378\n",
       "1  pivoted_normalization  0.069566  0.195017"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 2\n",
    "# stemming configuation or stopwords: termpipelines - Stopwords\n",
    "# languages and tokenisation: tokeniser - UTFTokeniser\n",
    "\n",
    "bm25_wt = pt.BatchRetrieve(index2, wmodel=bm25_weighting)\n",
    "p_n_wt = pt.BatchRetrieve(index2, wmodel=pivoted_normalization_weighting)\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25_wt, p_n_wt],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25\",  \"pivoted_normalization\"], \n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.074178</td>\n",
       "      <td>0.199323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pivoted_normalization</td>\n",
       "      <td>0.068971</td>\n",
       "      <td>0.194223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name       map      ndcg\n",
       "0                   BM25  0.074178  0.199323\n",
       "1  pivoted_normalization  0.068971  0.194223"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 3\n",
    "# stemming configuation or stopwords: termpipelines - PorterStemmer\n",
    "# languages and tokenisation: tokeniser - UTFTwitterTokeniser\n",
    "\n",
    "bm25_wt = pt.BatchRetrieve(index3, wmodel=bm25_weighting)\n",
    "p_n_wt = pt.BatchRetrieve(index3, wmodel=pivoted_normalization_weighting)\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25_wt, p_n_wt],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25\",  \"pivoted_normalization\"], \n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4 Tune BM25 (5 points)\n",
    "\n",
    "BM25 has several hyperparameters as we discussed in class. What effects might these have on the performance for this dataset? In Task 3.4, you will change the hyperparameters of your BM25 function and evaluate the performance. Perform at least five `Experiment` evaluations where you alter each hyperparameter (e.g., five where you change $b$, keeping the other two constant). You are welcome to do more evaluations as well to help understand the impact of each value on the performance. For full credit, you must find at least one set of hyperparameter values that outperforms the default values on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# b = 0.25\n",
    "def bm25_weighting_b025(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.25\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.40\n",
    "def bm25_weighting_b040(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.40\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.65\n",
    "def bm25_weighting_b065(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.65\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.72\n",
    "def bm25_weighting_b072(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.72\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.75 is the default setting\n",
    "\n",
    "# b = 0.88\n",
    "def bm25_weighting_b088(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.88\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.90\n",
    "def bm25_weighting_b090(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.90\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# b = 0.95\n",
    "def bm25_weighting_b095(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2  \n",
    "    b = 0.95\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "bm25_wt_b025 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b025)\n",
    "bm25_wt_b040 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b040)\n",
    "bm25_wt_b065 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b065)\n",
    "bm25_wt_b072 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b072)\n",
    "bm25_wt = pt.BatchRetrieve(index, wmodel=bm25_weighting)\n",
    "bm25_wt_b088 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b088)\n",
    "bm25_wt_b090 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b090)\n",
    "bm25_wt_b095 = pt.BatchRetrieve(index, wmodel=bm25_weighting_b095)\n",
    "\n",
    "\n",
    "bm25_b_sets = pt.Experiment(\n",
    "    [bm25_wt_b025, bm25_wt_b040, bm25_wt_b065, bm25_wt_b072, bm25_wt, bm25_wt_b088, bm25_wt_b090, bm25_wt_b095],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25_b0.25\", \"BM25_b0.40\",  \"BM25_b0.65\", \"BM25_b0.72\", \"BM25_b0.75\",\"BM25_b0.88\",\"BM25_b0.90\", \"BM25_b0.95\"], \n",
    "    eval_metrics=[\"map\",\"ndcg\",NDCG@5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>nDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25_b0.25</td>\n",
       "      <td>0.086744</td>\n",
       "      <td>0.225027</td>\n",
       "      <td>0.249203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25_b0.40</td>\n",
       "      <td>0.087623</td>\n",
       "      <td>0.226048</td>\n",
       "      <td>0.250537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25_b0.65</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>0.226467</td>\n",
       "      <td>0.253341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25_b0.72</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>0.226604</td>\n",
       "      <td>0.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25_b0.75</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BM25_b0.88</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.226480</td>\n",
       "      <td>0.253382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BM25_b0.90</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.226544</td>\n",
       "      <td>0.253489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25_b0.95</td>\n",
       "      <td>0.087594</td>\n",
       "      <td>0.226450</td>\n",
       "      <td>0.252313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       map      ndcg    nDCG@5\n",
       "0  BM25_b0.25  0.086744  0.225027  0.249203\n",
       "1  BM25_b0.40  0.087623  0.226048  0.250537\n",
       "2  BM25_b0.65  0.087648  0.226467  0.253341\n",
       "3  BM25_b0.72  0.087792  0.226604  0.253500\n",
       "4  BM25_b0.75  0.087705  0.226371  0.253002\n",
       "5  BM25_b0.88  0.087817  0.226480  0.253382\n",
       "6  BM25_b0.90  0.087863  0.226544  0.253489\n",
       "7  BM25_b0.95  0.087594  0.226450  0.252313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the results above, we can find that the hpyerparameter sets {k1=1.2, k3=8, b=0.72}, {k1=1.2, k3=8, b=0.88}, and {k1=1.2, k3=8, b=0.90} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\n"
     ]
    }
   ],
   "source": [
    "display(bm25_b_sets)\n",
    "print(\"From the results above, we can find that the hpyerparameter sets {k1=1.2, k3=8, b=0.72}, {k1=1.2, k3=8, b=0.88}, and {k1=1.2, k3=8, b=0.90} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# k1 = 1.2 is the default setting\n",
    "\n",
    "# k1 = 1.3\n",
    "def bm25_weighting_k113(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.3 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.4\n",
    "def bm25_weighting_k114(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.4 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.5\n",
    "def bm25_weighting_k115(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.5 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.6\n",
    "def bm25_weighting_k116(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.6 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.7\n",
    "def bm25_weighting_k117(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.7\n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.8\n",
    "def bm25_weighting_k118(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.8 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k1 = 1.9\n",
    "def bm25_weighting_k119(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.9 \n",
    "    b = 0.75\n",
    "    k3 = 8\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "bm25_wt = pt.BatchRetrieve(index, wmodel=bm25_weighting)\n",
    "bm25_wt_k113 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k113)\n",
    "bm25_wt_k114 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k114)\n",
    "bm25_wt_k115 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k115)\n",
    "bm25_wt_k116 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k116)\n",
    "bm25_wt_k117 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k117)\n",
    "bm25_wt_k118 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k118)\n",
    "bm25_wt_k119 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k119)\n",
    "\n",
    "\n",
    "bm25_k1_sets = pt.Experiment(\n",
    "    [bm25_wt, bm25_wt_k113, bm25_wt_k114, bm25_wt_k115, bm25_wt_k116, bm25_wt_k117, bm25_wt_k118, bm25_wt_k119],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25_k1 1.2\", \"BM25_k1 1.3\",  \"BM25_k1 1.4\", \"BM25_k1 1.5\", \"BM25_k1 1.6\",\"BM25_k1 1.7\",\"BM25_k1 1.8\", \"BM25_k1 1.9\"], \n",
    "    eval_metrics=[\"map\",\"ndcg\",NDCG@5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>nDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25_k1 1.2</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25_k1 1.3</td>\n",
       "      <td>0.087869</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.253845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25_k1 1.4</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>0.226629</td>\n",
       "      <td>0.253844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25_k1 1.5</td>\n",
       "      <td>0.087884</td>\n",
       "      <td>0.226408</td>\n",
       "      <td>0.253279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25_k1 1.6</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.226625</td>\n",
       "      <td>0.253078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BM25_k1 1.7</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.226404</td>\n",
       "      <td>0.252692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BM25_k1 1.8</td>\n",
       "      <td>0.088004</td>\n",
       "      <td>0.226690</td>\n",
       "      <td>0.252868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25_k1 1.9</td>\n",
       "      <td>0.087911</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.252731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name       map      ndcg    nDCG@5\n",
       "0  BM25_k1 1.2  0.087705  0.226371  0.253002\n",
       "1  BM25_k1 1.3  0.087869  0.226553  0.253845\n",
       "2  BM25_k1 1.4  0.087899  0.226629  0.253844\n",
       "3  BM25_k1 1.5  0.087884  0.226408  0.253279\n",
       "4  BM25_k1 1.6  0.087983  0.226625  0.253078\n",
       "5  BM25_k1 1.7  0.087813  0.226404  0.252692\n",
       "6  BM25_k1 1.8  0.088004  0.226690  0.252868\n",
       "7  BM25_k1 1.9  0.087911  0.226562  0.252731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the results above, we can find that the hpyerparameter sets {k1=1.3-1.6, k3=8, b=0.75} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\n"
     ]
    }
   ],
   "source": [
    "display(bm25_k1_sets)\n",
    "print(\"From the results above, we can find that the hpyerparameter sets {k1=1.3-1.6, k3=8, b=0.75} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# k3 = 1.2\n",
    "def bm25_weighting_k31p2(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 1.2\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 2\n",
    "def bm25_weighting_k32(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 2\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 3\n",
    "def bm25_weighting_k33(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 3\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 4\n",
    "def bm25_weighting_k34(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 4\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 6\n",
    "def bm25_weighting_k36(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 6\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 8 is the default setting\n",
    "\n",
    "# k3 = 10\n",
    "def bm25_weighting_k310(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 10\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "# k3 = 12\n",
    "def bm25_weighting_k312(keyFreq, posting, entryStats, collStats):\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection.\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k1 = 1.2 \n",
    "    b = 0.75\n",
    "    k3 = 12\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    \n",
    "    variant_IDF = math.log((N-df+0.5)/(df+0.5))\n",
    "    variant_TF = (k1+1)*c_t_D / (k1*(1-b+b*Ld/Lavg)+c_t_D)\n",
    "    normalized_QTF = (k3+1)*c_t_Q / (k3+c_t_Q)\n",
    "    \n",
    "    sim_term = variant_IDF * variant_TF * normalized_QTF\n",
    "    return sim_term\n",
    "\n",
    "bm25_wt_k31p2 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k31p2)\n",
    "bm25_wt_k32 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k32)\n",
    "bm25_wt_k33 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k33)\n",
    "bm25_wt_k34 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k34)\n",
    "bm25_wt_k36 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k36)\n",
    "bm25_wt_k38 = pt.BatchRetrieve(index, wmodel=bm25_weighting)\n",
    "bm25_wt_k310 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k310)\n",
    "bm25_wt_k312 = pt.BatchRetrieve(index, wmodel=bm25_weighting_k312)\n",
    "\n",
    "\n",
    "\n",
    "bm25_k3_sets = pt.Experiment(\n",
    "    [bm25_wt_k31p2, bm25_wt_k32, bm25_wt_k33, bm25_wt_k34, bm25_wt_k36, bm25_wt_k38,  bm25_wt_k310, bm25_wt_k312],\n",
    "    nf_dataset.get_topics(variant='title'),\n",
    "    nf_dataset.get_qrels(),\n",
    "    names=[\"BM25_k3 1.2\", \"BM25_k3 2.0\",  \"BM25_k3 3.0\", \"BM25_k3 4.0\", \"BM25_k3 6.0\",\"BM25_k3 8.0\",\"BM25_k3 10.\", \"BM25_k3 12.\"], \n",
    "    eval_metrics=[\"map\",\"ndcg\",NDCG@5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>nDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25_k3 1.2</td>\n",
       "      <td>0.087739</td>\n",
       "      <td>0.226405</td>\n",
       "      <td>0.253318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25_k3 2.0</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.252945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25_k3 3.0</td>\n",
       "      <td>0.087704</td>\n",
       "      <td>0.226364</td>\n",
       "      <td>0.252945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25_k3 4.0</td>\n",
       "      <td>0.087706</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25_k3 6.0</td>\n",
       "      <td>0.087706</td>\n",
       "      <td>0.226372</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BM25_k3 8.0</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BM25_k3 10.</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25_k3 12.</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>0.253002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name       map      ndcg    nDCG@5\n",
       "0  BM25_k3 1.2  0.087739  0.226405  0.253318\n",
       "1  BM25_k3 2.0  0.087708  0.226368  0.252945\n",
       "2  BM25_k3 3.0  0.087704  0.226364  0.252945\n",
       "3  BM25_k3 4.0  0.087706  0.226371  0.253002\n",
       "4  BM25_k3 6.0  0.087706  0.226372  0.253002\n",
       "5  BM25_k3 8.0  0.087705  0.226371  0.253002\n",
       "6  BM25_k3 10.  0.087705  0.226371  0.253002\n",
       "7  BM25_k3 12.  0.087705  0.226371  0.253002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the results above, we can find that the hpyerparameter sets {k1=1.2, k3=1.2, b=0.75} {k1=1.2, k3=4, b=0.75} and {k1=1.2, k3=6, b=0.75} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\n"
     ]
    }
   ],
   "source": [
    "display(bm25_k3_sets)\n",
    "print(\"From the results above, we can find that the hpyerparameter sets {k1=1.2, k3=1.2, b=0.75} {k1=1.2, k3=4, b=0.75} and {k1=1.2, k3=6, b=0.75} outperform the default values {k1=1.2, k3=8, b=0.75} on this dataset on the metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5 Write up your observations (10 points)\n",
    "\n",
    "Did BM25 outperform Pivoted Normalization? How did the choice in hyperparameters affect performance? In Task 3.5, you should write at least five sentences describe your observations on the performance. You should also generate separate plots showing the performance as you change each BM25 hyperparameter (three plots total); for example, one plot would have NDCG on the y-axis and $b$ on the x-axis and show NDCG changes relative the value of $b$. Use a line plot for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ndcg with respect to hyperparameter b')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO (in your write-up document)\n",
    "\n",
    "# see si650_hw2_sijuntao.pdf for the description about the observations on the performance\n",
    "\n",
    "# You should also generate separate plots showing the performance as you change each BM25 hyperparameter (three plots total); \n",
    "# for example, one plot would have NDCG on the y-axis and b on the x-axis and show NDCG changes relative the value of 𝑏. \n",
    "# Use a line plot for this.\n",
    "\n",
    "# for hyperparameter b\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = bm25_b_sets.copy()\n",
    "df[\"b_val\"] = df[\"name\"].str[-4:].astype(float)\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "plot = sns.lineplot(data = df, x = \"b_val\", y = \"ndcg\" )\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_xlabel(\"b\")\n",
    "ax.set_ylabel(\"ndcg\")\n",
    "ax.set_title(\"ndcg with respect to hyperparameter b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ndcg with respect to hyperparameter k1')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = bm25_k1_sets.copy()\n",
    "df[\"k1_val\"] = df[\"name\"].str[-3:].astype(float)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(6, 4))\n",
    "plot1 = sns.lineplot(data = df, x = \"k1_val\", y = \"ndcg\" )\n",
    "ax1.set_xlim(1,2)\n",
    "ax1.set_xlabel(\"k1\")\n",
    "ax1.set_ylabel(\"ndcg\")\n",
    "ax1.set_title(\"ndcg with respect to hyperparameter k1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ndcg with respect to hyperparameter k3')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = bm25_k3_sets.copy()\n",
    "df[\"k3_val\"] = df[\"name\"].str[-3:].astype(float)\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(6, 4))\n",
    "plot3 = sns.lineplot(data = df, x = \"k3_val\", y = \"ndcg\" )\n",
    "ax3.set_xlim(1,13)\n",
    "ax3.set_xlabel(\"k3\")\n",
    "ax3.set_ylabel(\"ndcg\")\n",
    "ax3.set_title(\"ndcg with respect to hyperparameter k3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1 Implement your custom weighting function (25 points)\n",
    "\n",
    "The last part of the assignment will have you implement at least one retrieval function _different_ from BM25, Dirichlet Prior, and Pivoted Length Normalization (and any variations of these). You will be graded based on your best performing function. You’ll get full credit if your retrieval function can beat the provided baseline in the dataset, which is an untuned BM25 using PyTerrier's default parameters. By \"beat,\"' we mean that your implemented function and your choice of parameters should reach higher NDCG than the baseline on Kaggle for our dataset, which you can check at any time by running an Experiment with PyTerrier's BM25 implementation. _Full credit for this function depends on whether it can surpass an untuned BM25 ranking of the same dataset._\n",
    "\n",
    "Most of your time in this part of the assignment will be spent trying to see what kinds of adjustments you can make to a ranking function improve. In past years, nearly all students have managed to outperform BM25 so it is very much possible. You are welcomed to be creative in your approaches as well. The intent of this part is to help you understand how different parts of the function help or hurt ranking, which often is a very empirical and hands-on process when trying to fine-tune a ranker for a particular dataset.\n",
    "\n",
    "**Note:** Simply varying the value of parameters in Okapi/BM25, Dirichlet Prior or Pivoted Length Normalization does not count as a new retrieval function. The variations of any of the algorithms listed in the slides or in the textbooks also do not count as new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_weighting(keyFreq, posting, entryStats, collStats):\n",
    "    '''\n",
    "    Computes the Pivoted Normalization score of this document for a given query\n",
    "    \n",
    "    :param keyFrequency(float): the weight of the term in the query, usually 1 except during PRF.\n",
    "    :param posting(Posting): access to the information about the occurrence of the term in the current document (frequency, document length etc).\n",
    "    :param entryStats(EntryStatistics): access to the information about the occurrence of the term in the whole index (document frequency, etc.).\n",
    "    :param collStats(CollectionStatistics): access to the information about the index as a whole (number of documents, etc).\n",
    "    :return: the Pivoted Normalization score of this document for the given query\n",
    "    '''\n",
    "    N = collStats.getNumberOfDocuments()         # the total number of documents in the collection\n",
    "    df = entryStats.getDocumentFrequency()       # the number of documents that the term occurs in\n",
    "    k = 2.2\n",
    "    c_t_D = posting.getFrequency()               # the frequency of the term in the current document, in tokens\n",
    "    Ld = posting.getDocumentLength()             # the length of the document of the current posting in tokens\n",
    "    Lavg = collStats.getAverageDocumentLength()  # the documents' average length\n",
    "    c_t_Q = keyFreq                              # the frequency of the term in the query\n",
    "    cf = entryStats.getFrequency()               # the frequency (total number of occurrences) of the term\n",
    "    tot_num = collStats.getNumberOfUniqueTerms() # the total number of unique terms in the collection\n",
    "    \n",
    "    variant2_TF = c_t_D * math.log(1.0 + (k * Lavg) / Ld)\n",
    "    QTF = c_t_Q\n",
    "    ln2_IDF = math.log(math.e,2) * math.log((N+1)/(df+0.5))   \n",
    "    CF =  (cf + 1) / (df * (variant2_TF + 1))\n",
    "\n",
    "\n",
    "    sim_term = ln2_IDF * variant2_TF * QTF * CF\n",
    "    return sim_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 Describe what your function does and why you designed it that way (10 points)\n",
    "=\n",
    "\n",
    "In the write-up document, write a paragraph of at least five sentences **explaining** what your function does, how you designed in, and why you decide to choose those hyperparameter values. You will lose points if you cannot explain why your function can reach a higher performance. You can use the constraints we discussed at the end of Lecture 4 too if those are helpful for motivating particular design choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in separate document\n",
    "\n",
    "# see si650_hw2_sijuntao.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3 Build the index for our test collection (0 points, but necessary for 4.1)\n",
    "\n",
    "In the earlier tasks, we used NFCorpus which is for medical IR. What if we switched the domain slightly? For Task 4, we'll use the [CORD19 dataset](https://github.com/allenai/cord19), which is an IR dataset for Covid-19 questions created by AI2. Please download the dataset from the [Kaggle InClass competition site](https://www.kaggle.com/t/46e34d98356c4ae7b91517a6564a7979). Please do not download this data from other sources as this might hurt your final performance. You are welcome to adjust the preprocessing steps to give you better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:18:30.440 [main] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (8is9x9sc) - further warnings are suppressed\n",
      "19:19:34.217 [main] WARN org.terrier.structures.indexing.Indexer - Indexed 17 empty documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./c19_df_index/data.properties'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_dataset = pd.read_csv(\"queries.csv\")\n",
    "cord19_dataset = pd.read_csv(\"documents.csv\").rename(columns = {\"doc_id\":\"docno\",\"document\":\"text\"})\n",
    "\n",
    "index_dir = './c19_df_index'\n",
    "indexer = pt.DFIndexer(index_dir, overwrite=True)\n",
    "index_ref = indexer.index(cord19_dataset[\"text\"], cord19_dataset[\"docno\"])\n",
    "index_ref.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 171332\n",
      "Number of terms: 156504\n",
      "Number of postings: 11120054\n",
      "Number of fields: 0\n",
      "Number of tokens: 17546619\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_df = pt.IndexFactory.of(index_ref)\n",
    "print(index_df.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.4 Upload rankings for CORD19 to the KaggleInClass (0 points, but necessary for 4.1)\n",
    "\n",
    "Finally, let's see how your custom ranking function does! Use your custom weighting to score the documents for each query in CORD 19 below. Upload your relevance judgments to the [Kaggle InClass leaderboard](https://www.kaggle.com/t/46e34d98356c4ae7b91517a6564a7979) to see how well it works. Using your best parameters, for each query, report the most relevant five documents, using their document ID. A sample submission for just one query would look like the following as a table (you submit a .csv file):\n",
    "\n",
    "| QueryId | DocumentId | \n",
    "| --- | --- | \n",
    "| 116 | 1502 | \n",
    "| 116 | 6437 | \n",
    "| 116 | 2322 |\n",
    "| 116 | 6087 |\n",
    "| 116 | 2978 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n",
      "/Users/junsi/opt/anaconda3/lib/python3.9/site-packages/pyterrier/transformer.py:269: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  return self.transform(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ccl9aui</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75773gwg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne5r4d4b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es7q6c90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4dtk1kyh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30dhqh0g</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xbze5s3c</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fbpdyg2i</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4nrpcado</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binxayw2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       docno  qid\n",
       "0   8ccl9aui    1\n",
       "1   75773gwg    1\n",
       "2   ne5r4d4b    1\n",
       "3   es7q6c90    1\n",
       "4   4dtk1kyh    1\n",
       "..       ...  ...\n",
       "0   30dhqh0g   50\n",
       "1   xbze5s3c   50\n",
       "2   fbpdyg2i   50\n",
       "3   4nrpcado   50\n",
       "4   binxayw2   50\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "mc_wt_c19 = pt.BatchRetrieve(index_df, wmodel=my_custom_weighting)\n",
    "\n",
    "first_q = queries_dataset.loc[0,\"query\"]\n",
    "final_df = mc_wt_c19(first_q).head(5).loc[:,[\"docno\"]]\n",
    "final_df[\"qid\"] = [0+1] *5\n",
    "\n",
    "for i in range(1, len(queries_dataset)):\n",
    "    temp_q = queries_dataset.loc[i,\"query\"]\n",
    "    temp_df = mc_wt_c19(temp_q).head(5).loc[:,[\"docno\"]]\n",
    "    temp_df[\"qid\"] = [i+1] *5\n",
    "    final_df = pd.concat([final_df, temp_df])\n",
    "    \n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[[\"qid\",\"docno\"]]\n",
    "final_df.to_csv(\"final_best_v3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECIR 2021 Tutorial Notebook - Part 1.ipynb",
   "provenance": [
    {
     "file_id": "1kWCNf3QlQ4bX5YCM9OJBaaLikoTFCd5A",
     "timestamp": 1615914442515
    },
    {
     "file_id": "17Pihqt_C8DFzqlomTUks-5stNzNFjrAn",
     "timestamp": 1611078807322
    },
    {
     "file_id": "121AtOADdFd2VVAX5hcJX0WNBNt2_QHDu",
     "timestamp": 1609952873856
    },
    {
     "file_id": "1o4RTKOutf_FlMyPdEPkRyutnbY26JXMf",
     "timestamp": 1571324862553
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
